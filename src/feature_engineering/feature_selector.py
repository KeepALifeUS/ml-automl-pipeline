"""
Advanced Feature Selection for AutoML Pipeline
Implements enterprise patterns for robust feature selection
"""

import logging
from typing import Dict, List, Optional, Tuple, Union, Any, Callable
from dataclasses import dataclass
from abc import ABC, abstractmethod
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from sklearn.feature_selection import (
    SelectKBest, SelectPercentile, SelectFromModel,
    f_regression, f_classif, mutual_info_regression, mutual_info_classif,
    chi2, RFE, RFECV
)
from sklearn.linear_model import LassoCV, ElasticNetCV
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_squared_error, accuracy_score
from sklearn.model_selection import cross_val_score
import xgboost as xgb
from loguru import logger
from pydantic import BaseModel, Field
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
from scipy import stats
from scipy.stats import pearsonr, spearmanr
import matplotlib.pyplot as plt
import seaborn as sns

from ..utils.config_manager import AutoMLConfig


class SelectionMethod(Enum):
    """Methods –æ—Ç–±–æ—Ä–∞ features"""
    STATISTICAL = "statistical"
    MODEL_BASED = "model_based"
    UNIVARIATE = "univariate"
    RECURSIVE = "recursive"
    CORRELATION = "correlation"
    MUTUAL_INFO = "mutual_info"
    VARIANCE = "variance"
    LASSO = "lasso"
    ELASTIC_NET = "elastic_net"


@dataclass
class FeatureSelectionResult:
    """Result –æ—Ç–±–æ—Ä–∞ features"""
    selected_features: List[str]
    feature_scores: Dict[str, float]
    selection_metadata: Dict[str, Any]
    eliminated_features: List[str]
    selection_time: float
    method_used: str


class BaseFeatureSelector(ABC):
    """Base –∫–ª–∞—Å—Å for —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ features -  pattern"""
    
    @abstractmethod
    def select(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> FeatureSelectionResult:
        """–í—ã–±—Ä–∞—Ç—å features"""
        pass
    
    @abstractmethod
    def get_selection_params(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å parameters —Å–µ–ª–µ–∫—Ü–∏–∏"""
        pass


class StatisticalFeatureSelector(BaseFeatureSelector):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä features"""
    
    def __init__(self, method: str = 'f_regression', k: int = 50, percentile: float = 50):
        self.method = method
        self.k = k
        self.percentile = percentile
        self.selector = None
        
        # Select —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π functions
        self.stat_functions = {
            'f_regression': f_regression,
            'f_classif': f_classif,
            'mutual_info_regression': mutual_info_regression,
            'mutual_info_classif': mutual_info_classif,
            'chi2': chi2
        }
        
    def select(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> FeatureSelectionResult:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π selection features"""
        import time
        start_time = time.time()
        
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π selection features method {self.method}")
        
        try:
            # Select functions —Å–∫–æ—Ä–∏–Ω–≥–∞
            score_func = self.stat_functions.get(self.method, f_regression)
            
            # Determine strategies –æ—Ç–±–æ—Ä–∞
            if self.k > 0:
                self.selector = SelectKBest(score_func=score_func, k=min(self.k, X.shape[1]))
            else:
                self.selector = SelectPercentile(score_func=score_func, percentile=self.percentile)
            
            # –û—á–∏—Å—Ç–∫–∞ data
            X_clean = X.fillna(0).replace([np.inf, -np.inf], 0)
            y_clean = y.fillna(y.mean()) if y.isna().any() else y
            
            # Select features
            X_selected = self.selector.fit_transform(X_clean, y_clean)
            
            # Get –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö features
            selected_mask = self.selector.get_support()
            selected_features = X.columns[selected_mask].tolist()
            eliminated_features = X.columns[~selected_mask].tolist()
            
            # Get scores
            scores = self.selector.scores_
            feature_scores = dict(zip(X.columns, scores))
            
            processing_time = time.time() - start_time
            
            result = FeatureSelectionResult(
                selected_features=selected_features,
                feature_scores=feature_scores,
                selection_metadata={
                    'method': self.method,
                    'k_features': len(selected_features),
                    'original_features': X.shape[1],
                    'reduction_ratio': 1 - len(selected_features) / X.shape[1]
                },
                eliminated_features=eliminated_features,
                selection_time=processing_time,
                method_used=f"statistical_{self.method}"
            )
            
            logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(selected_features)} from {X.shape[1]} features")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç–±–æ—Ä–∞: {e}")
            return FeatureSelectionResult(
                selected_features=list(X.columns),
                feature_scores={col: 0.0 for col in X.columns},
                selection_metadata={'error': str(e)},
                eliminated_features=[],
                selection_time=time.time() - start_time,
                method_used=f"statistical_{self.method}_failed"
            )
    
    def get_selection_params(self) -> Dict[str, Any]:
        return {
            'method': self.method,
            'k': self.k,
            'percentile': self.percentile
        }


class ModelBasedFeatureSelector(BaseFeatureSelector):
    """–ú–æ–¥–µ–ª—å–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä features"""
    
    def __init__(self, model_type: str = 'random_forest', max_features: int = 100):
        self.model_type = model_type
        self.max_features = max_features
        self.model = None
        
    def _get_model(self, task_type: str = 'regression'):
        """–ü–æ–ª—É—á–∏—Ç—å model for –æ—Ç–±–æ—Ä–∞ features"""
        if self.model_type == 'random_forest':
            if task_type == 'regression':
                return RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
            else:
                return RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)
        elif self.model_type == 'xgboost':
            if task_type == 'regression':
                return xgb.XGBRegressor(n_estimators=50, random_state=42, n_jobs=-1)
            else:
                return xgb.XGBClassifier(n_estimators=50, random_state=42, n_jobs=-1)
        else:
            # By default Random Forest
            return RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
    
    def select(self, X: pd.DataFrame, y: pd.Series, task_type: str = 'regression') -> FeatureSelectionResult:
        """–ú–æ–¥–µ–ª—å–Ω—ã–π selection features"""
        import time
        start_time = time.time()
        
        logger.info(f"ü§ñ –ú–æ–¥–µ–ª—å–Ω—ã–π selection features with {self.model_type}")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ data
            X_clean = X.fillna(0).replace([np.inf, -np.inf], 0)
            y_clean = y.fillna(y.mean()) if y.isna().any() else y
            
            # Get model
            self.model = self._get_model(task_type)
            
            # Training model
            self.model.fit(X_clean, y_clean)
            
            # Get –≤–∞–∂–Ω–æ—Å—Ç–∏ features
            if hasattr(self.model, 'feature_importances_'):
                importances = self.model.feature_importances_
            elif hasattr(self.model, 'coef_'):
                importances = np.abs(self.model.coef_)
            else:
                # Fallback: use –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
                importances = np.abs(X_clean.corrwith(y_clean).fillna(0).values)
            
            # Create —Å–ª–æ–≤–∞—Ä—è –≤–∞–∂–Ω–æ—Å—Ç–∏
            feature_scores = dict(zip(X.columns, importances))
            
            # Select —Ç–æ–ø features
            sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)
            selected_features = [f[0] for f in sorted_features[:self.max_features]]
            eliminated_features = [f[0] for f in sorted_features[self.max_features:]]
            
            processing_time = time.time() - start_time
            
            result = FeatureSelectionResult(
                selected_features=selected_features,
                feature_scores=feature_scores,
                selection_metadata={
                    'model_type': self.model_type,
                    'task_type': task_type,
                    'max_features': self.max_features,
                    'original_features': X.shape[1],
                    'mean_importance': np.mean(importances),
                    'std_importance': np.std(importances)
                },
                eliminated_features=eliminated_features,
                selection_time=processing_time,
                method_used=f"model_{self.model_type}"
            )
            
            logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(selected_features)} —Ç–æ–ø features")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error –º–æ–¥–µ–ª—å–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞: {e}")
            return FeatureSelectionResult(
                selected_features=list(X.columns)[:self.max_features],
                feature_scores={col: 0.0 for col in X.columns},
                selection_metadata={'error': str(e)},
                eliminated_features=[],
                selection_time=time.time() - start_time,
                method_used=f"model_{self.model_type}_failed"
            )
    
    def get_selection_params(self) -> Dict[str, Any]:
        return {
            'model_type': self.model_type,
            'max_features': self.max_features
        }


class CorrelationFeatureSelector(BaseFeatureSelector):
    """–°–µ–ª–µ–∫—Ç–æ—Ä on –æ—Å–Ω–æ–≤–µ correlation"""
    
    def __init__(self, correlation_threshold: float = 0.95, target_correlation_min: float = 0.01):
        self.correlation_threshold = correlation_threshold
        self.target_correlation_min = target_correlation_min
        
    def select(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> FeatureSelectionResult:
        """Select features by correlation"""
        import time
        start_time = time.time()
        
        logger.info("üîó –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π selection features")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ data
            X_clean = X.fillna(0).replace([np.inf, -np.inf], 0)
            y_clean = y.fillna(y.mean()) if y.isna().any() else y
            
            # Remove features with low correlation to the target variable
            target_correlations = X_clean.corrwith(y_clean).abs()
            high_target_corr_features = target_correlations[
                target_correlations >= self.target_correlation_min
            ].index.tolist()
            
            if not high_target_corr_features:
                logger.warning("‚ö†Ô∏è No features with sufficient correlation to the target variable")
                high_target_corr_features = list(X.columns)
            
            X_filtered = X_clean[high_target_corr_features]
            
            # Remove –≤—ã—Å–æ–∫–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏—Ö between —Å–æ–±–æ–π features
            correlation_matrix = X_filtered.corr().abs()
            
            # Search pairs with high correlation
            high_corr_pairs = []
            for i in range(len(correlation_matrix.columns)):
                for j in range(i+1, len(correlation_matrix.columns)):
                    if correlation_matrix.iloc[i, j] >= self.correlation_threshold:
                        col_i = correlation_matrix.columns[i]
                        col_j = correlation_matrix.columns[j]
                        
                        # –û—Å—Ç–∞–≤–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫ with –±–æ–ª—å—à–µ–π correlation with target variable
                        target_corr_i = abs(target_correlations[col_i])
                        target_corr_j = abs(target_correlations[col_j])
                        
                        if target_corr_i >= target_corr_j:
                            high_corr_pairs.append(col_j)
                        else:
                            high_corr_pairs.append(col_i)
            
            # Remove –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            features_to_remove = list(set(high_corr_pairs))
            selected_features = [f for f in high_target_corr_features if f not in features_to_remove]
            
            # Create scores (correlation with target variable)
            feature_scores = target_correlations.to_dict()
            
            processing_time = time.time() - start_time
            
            result = FeatureSelectionResult(
                selected_features=selected_features,
                feature_scores=feature_scores,
                selection_metadata={
                    'correlation_threshold': self.correlation_threshold,
                    'target_correlation_min': self.target_correlation_min,
                    'removed_high_corr': len(features_to_remove),
                    'removed_low_target_corr': len(X.columns) - len(high_target_corr_features)
                },
                eliminated_features=[f for f in X.columns if f not in selected_features],
                selection_time=processing_time,
                method_used="correlation"
            )
            
            logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(selected_features)} features after –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞: {e}")
            return FeatureSelectionResult(
                selected_features=list(X.columns),
                feature_scores={col: 0.0 for col in X.columns},
                selection_metadata={'error': str(e)},
                eliminated_features=[],
                selection_time=time.time() - start_time,
                method_used="correlation_failed"
            )
    
    def get_selection_params(self) -> Dict[str, Any]:
        return {
            'correlation_threshold': self.correlation_threshold,
            'target_correlation_min': self.target_correlation_min
        }


class VarianceFeatureSelector(BaseFeatureSelector):
    """–°–µ–ª–µ–∫—Ç–æ—Ä on –æ—Å–Ω–æ–≤–µ –¥–∏—Å–ø–µ—Ä—Å–∏–∏"""
    
    def __init__(self, variance_threshold: float = 0.0):
        self.variance_threshold = variance_threshold
        
    def select(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> FeatureSelectionResult:
        """Select features by –¥–∏—Å–ø–µ—Ä—Å–∏–∏"""
        import time
        start_time = time.time()
        
        logger.info("üìà Select features by –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ data
            X_clean = X.fillna(0).replace([np.inf, -np.inf], 0)
            
            # Computation –¥–∏—Å–ø–µ—Ä—Å–∏–π
            variances = X_clean.var()
            
            # Select features with –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π –≤—ã—à–µ threshold
            high_var_features = variances[variances > self.variance_threshold].index.tolist()
            
            feature_scores = variances.to_dict()
            eliminated_features = [f for f in X.columns if f not in high_var_features]
            
            processing_time = time.time() - start_time
            
            result = FeatureSelectionResult(
                selected_features=high_var_features,
                feature_scores=feature_scores,
                selection_metadata={
                    'variance_threshold': self.variance_threshold,
                    'mean_variance': variances.mean(),
                    'removed_low_variance': len(eliminated_features)
                },
                eliminated_features=eliminated_features,
                selection_time=processing_time,
                method_used="variance"
            )
            
            logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(high_var_features)} features with high –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error –æ—Ç–±–æ—Ä–∞ by –¥–∏—Å–ø–µ—Ä—Å–∏–∏: {e}")
            return FeatureSelectionResult(
                selected_features=list(X.columns),
                feature_scores={col: 0.0 for col in X.columns},
                selection_metadata={'error': str(e)},
                eliminated_features=[],
                selection_time=time.time() - start_time,
                method_used="variance_failed"
            )
    
    def get_selection_params(self) -> Dict[str, Any]:
        return {'variance_threshold': self.variance_threshold}


class AdvancedFeatureSelector:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä features with –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
    Implements enterprise patterns
    """
    
    def __init__(self, config: Optional[AutoMLConfig] = None):
        self.config = config or AutoMLConfig()
        self.selectors: Dict[str, BaseFeatureSelector] = {}
        self._setup_selectors()
        
    def _setup_selectors(self):
        """Configure —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤"""
        logger.info("üîß Configure —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ features...")
        
        selection_config = self.config.feature_selection
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä
        self.selectors['statistical'] = StatisticalFeatureSelector(
            method=selection_config.get('statistical_method', 'f_regression'),
            k=selection_config.get('statistical_k', 50),
            percentile=selection_config.get('statistical_percentile', 50)
        )
        
        # –ú–æ–¥–µ–ª—å–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
        self.selectors['model'] = ModelBasedFeatureSelector(
            model_type=selection_config.get('model_type', 'random_forest'),
            max_features=selection_config.get('model_max_features', 100)
        )
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
        self.selectors['correlation'] = CorrelationFeatureSelector(
            correlation_threshold=selection_config.get('correlation_threshold', 0.95),
            target_correlation_min=selection_config.get('target_correlation_min', 0.01)
        )
        
        # –°–µ–ª–µ–∫—Ç–æ—Ä by –¥–∏—Å–ø–µ—Ä—Å–∏–∏
        self.selectors['variance'] = VarianceFeatureSelector(
            variance_threshold=selection_config.get('variance_threshold', 0.0)
        )
        
        logger.info(f"‚úÖ –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ {len(self.selectors)} —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤")
    
    def select_features(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        methods: Optional[List[str]] = None,
        task_type: str = 'regression',
        ensemble_selection: bool = True
    ) -> FeatureSelectionResult:
        """
        Main method –æ—Ç–±–æ—Ä–∞ features
        
        Args:
            X: Matrix features
            y: Target variable
            methods: Methods for use
            task_type: –¢–∏–ø tasks (regression/classification)
            ensemble_selection: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ensemble methods
        """
        logger.info("üéØ Launch –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –æ—Ç–±–æ—Ä–∞ features...")
        
        if methods is None:
            methods = list(self.selectors.keys())
        
        results = {}
        
        # Apply each method
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
        ) as progress:
            task = progress.add_task("Select features...", total=len(methods))
            
            for method in methods:
                if method not in self.selectors:
                    continue
                    
                try:
                    progress.update(task, description=f"Method: {method}")
                    
                    if method == 'model':
                        result = self.selectors[method].select(X, y, task_type=task_type)
                    else:
                        result = self.selectors[method].select(X, y)
                    
                    results[method] = result
                    progress.advance(task)
                    
                except Exception as e:
                    logger.error(f"‚ùå Error in –º–µ—Ç–æ–¥–µ {method}: {e}")
                    progress.advance(task)
        
        if not results:
            logger.error("‚ùå –ù–∏ one method –æ—Ç–±–æ—Ä–∞ not —Å—Ä–∞–±–æ—Ç–∞–ª")
            return FeatureSelectionResult(
                selected_features=list(X.columns),
                feature_scores={col: 0.0 for col in X.columns},
                selection_metadata={'error': 'All methods failed'},
                eliminated_features=[],
                selection_time=0.0,
                method_used="failed"
            )
        
        if ensemble_selection and len(results) > 1:
            return self._ensemble_selection(X, y, results)
        else:
            # Use best method (with –Ω–∞–∏–±–æ–ª—å—à–∏–º number features)
            best_method = max(results.keys(), key=lambda m: len(results[m].selected_features))
            return results[best_method]
    
    def _ensemble_selection(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        results: Dict[str, FeatureSelectionResult]
    ) -> FeatureSelectionResult:
        """–ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π selection features"""
        import time
        start_time = time.time()
        
        logger.info("ü§ù –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π selection features...")
        
        # –ü–æ–¥—Å—á–µ—Ç votes for each –ø—Ä–∏–∑–Ω–∞–∫
        feature_votes = {}
        all_scores = {}
        
        for method, result in results.items():
            for feature in result.selected_features:
                feature_votes[feature] = feature_votes.get(feature, 0) + 1
                if feature in result.feature_scores:
                    if feature not in all_scores:
                        all_scores[feature] = []
                    all_scores[feature].append(result.feature_scores[feature])
        
        # Computation average scores
        average_scores = {}
        for feature, scores in all_scores.items():
            average_scores[feature] = np.mean(scores)
        
        # Determine threshold votes (minimum 2 –≥–æ–ª–æ—Å–∞ from 3+ methods)
        min_votes = max(2, len(results) // 2)
        selected_features = [
            feature for feature, votes in feature_votes.items()
            if votes >= min_votes
        ]
        
        # If —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ features, add —Ç–æ–ø by —Å–∫–æ—Ä–∞–º
        if len(selected_features) < 10:
            sorted_by_score = sorted(
                average_scores.items(),
                key=lambda x: x[1],
                reverse=True
            )
            for feature, _ in sorted_by_score:
                if feature not in selected_features:
                    selected_features.append(feature)
                    if len(selected_features) >= 20:  # –ú–∞–∫—Å–∏–º—É–º 20 features
                        break
        
        eliminated_features = [f for f in X.columns if f not in selected_features]
        processing_time = time.time() - start_time
        
        ensemble_result = FeatureSelectionResult(
            selected_features=selected_features,
            feature_scores=average_scores,
            selection_metadata={
                'ensemble_methods': list(results.keys()),
                'min_votes_threshold': min_votes,
                'feature_votes': feature_votes,
                'total_original_features': X.shape[1]
            },
            eliminated_features=eliminated_features,
            selection_time=processing_time,
            method_used="ensemble"
        )
        
        logger.info(f"‚úÖ Ensemble –æ—Ç–æ–±—Ä–∞–ª {len(selected_features)} features")
        return ensemble_result
    
    def plot_feature_importance(
        self,
        result: FeatureSelectionResult,
        top_n: int = 20,
        save_path: Optional[str] = None
    ):
        """Visualization –≤–∞–∂–Ω–æ—Å—Ç–∏ features"""
        try:
            # –¢–æ–ø N features by –≤–∞–∂–Ω–æ—Å—Ç–∏
            top_features = sorted(
                result.feature_scores.items(),
                key=lambda x: x[1],
                reverse=True
            )[:top_n]
            
            features, scores = zip(*top_features)
            
            plt.figure(figsize=(12, 8))
            sns.barplot(x=list(scores), y=list(features), palette='viridis')
            plt.title(f'–¢–æ–ø {top_n} features by –≤–∞–∂–Ω–æ—Å—Ç–∏ ({result.method_used})')
            plt.xlabel('–í–∞–∂–Ω–æ—Å—Ç—å features')
            plt.ylabel('Features')
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
            else:
                plt.show()
                
        except Exception as e:
            logger.error(f"‚ùå Error creation –≥—Ä–∞—Ñ–∏–∫–∞: {e}")
    
    def get_selection_report(self, result: FeatureSelectionResult) -> str:
        """Create –æ—Ç—á–µ—Ç–∞ by –æ—Ç–±–æ—Ä—É features"""
        report = f"""
=== –û–¢–ß–ï–¢ By –û–¢–ë–û–†–£ Features ===

Method: {result.method_used}
–í—Ä–µ–º—è execution: {result.selection_time:.2f}with

–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
- –ò—Å—Ö–æ–¥–Ω–æ–µ number features: {len(result.selected_features) + len(result.eliminated_features)}
- –û—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö features: {len(result.selected_features)}
- –ò—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö features: {len(result.eliminated_features)}
- Coefficient compression: {len(result.eliminated_features) / (len(result.selected_features) + len(result.eliminated_features)):.2%}

–¢–æ–ø-10 features by –≤–∞–∂–Ω–æ—Å—Ç–∏:
"""
        
        top_features = sorted(
            result.feature_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )[:10]
        
        for i, (feature, score) in enumerate(top_features, 1):
            report += f"{i:2d}. {feature}: {score:.4f}\n"
        
        report += f"\n–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {result.selection_metadata}"
        
        return report


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä use
    from ..utils.config_manager import AutoMLConfig
    
    # Create test data
    np.random.seed(42)
    n_samples, n_features = 1000, 100
    
    X = pd.DataFrame(
        np.random.randn(n_samples, n_features),
        columns=[f'feature_{i}' for i in range(n_features)]
    )
    
    # Create —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–π target variable
    # –ü–µ—Ä–≤—ã–µ 10 features –≤–∞–∂–Ω—ã–µ, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —à—É–º
    important_features = X.iloc[:, :10].values
    y = pd.Series(
        np.sum(important_features * np.random.randn(10), axis=1) + 
        0.1 * np.random.randn(n_samples)
    )
    
    # Create —Å–µ–ª–µ–∫—Ç–æ—Ä–∞
    config = AutoMLConfig()
    selector = AdvancedFeatureSelector(config)
    
    # Select features
    result = selector.select_features(X, y, ensemble_selection=True)
    
    print("=== Results –û–¢–ë–û–†–ê Features ===")
    print(f"–û—Ç–æ–±—Ä–∞–Ω–æ features: {len(result.selected_features)}")
    print(f"–í—Ä–µ–º—è –æ—Ç–±–æ—Ä–∞: {result.selection_time:.2f}with")
    print(f"Method: {result.method_used}")
    
    # –û—Ç—á–µ—Ç
    print(selector.get_selection_report(result))