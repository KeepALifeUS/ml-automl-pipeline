"""
Configuration Manager for AutoML Pipeline
Implements enterprise patterns for configuration management
"""

import logging
from typing import Dict, List, Optional, Union, Any
from dataclasses import dataclass, field
import os
import json
import yaml
from pathlib import Path
from pydantic import BaseSettings, Field, validator
from loguru import logger


@dataclass
class FeatureGenerationConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    enable_technical_indicators: bool = True
    enable_statistical_features: bool = True
    enable_polynomial_features: bool = True
    enable_tsfresh_features: bool = True
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
    technical_indicators_windows: List[int] = field(default_factory=lambda: [10, 20, 50])
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    statistical_windows: List[int] = field(default_factory=lambda: [5, 10, 20])
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    polynomial_degree: int = 2
    polynomial_max_features: int = 50
    polynomial_interaction_only: bool = True
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã TSFresh
    tsfresh_max_features: int = 30
    tsfresh_default_fc_parameters: str = "efficient"
    
    # –û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parallel_generation: bool = True
    max_features_per_generator: int = 100


@dataclass
class FeatureSelectionConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    enable_statistical_selection: bool = True
    enable_model_based_selection: bool = True
    enable_correlation_selection: bool = True
    enable_variance_selection: bool = True
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç–±–æ—Ä–∞
    statistical_method: str = "f_regression"  # f_regression, mutual_info_regression
    statistical_k: int = 50
    statistical_percentile: float = 50.0
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª—å–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞
    model_type: str = "random_forest"  # random_forest, xgboost
    model_max_features: int = 100
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞
    correlation_threshold: float = 0.95
    target_correlation_min: float = 0.01
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç–±–æ—Ä–∞ –ø–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
    variance_threshold: float = 0.0
    
    # –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π –æ—Ç–±–æ—Ä
    ensemble_selection: bool = True
    min_votes_threshold: int = 2


@dataclass
class HyperparameterOptimizationConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    default_optimizer: str = "optuna_tpe"  # optuna_tpe, optuna_random, gaussian_process
    n_trials: int = 100
    n_jobs: int = -1
    random_state: int = 42
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Optuna
    optuna_study_name_prefix: str = "automl_optimization"
    optuna_sampler_startup_trials: int = 10
    optuna_sampler_n_ei_candidates: int = 24
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã scikit-optimize
    skopt_n_initial_points: int = 10
    skopt_acq_func: str = "EI"  # EI, PI, LCB
    
    # –û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    cv_folds: int = 5
    scoring_metric: Optional[str] = None  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    timeout_per_trial: int = 300  # —Å–µ–∫—É–Ω–¥
    
    # Early stopping
    enable_pruning: bool = True
    pruning_min_trials: int = 20


@dataclass
class ModelSelectionConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ—Ç–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π"""
    enable_sklearn_models: bool = True
    enable_xgboost: bool = True
    enable_lightgbm: bool = True
    enable_catboost: bool = True
    
    # –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    sklearn_models: List[str] = field(default_factory=lambda: [
        'linear_regression', 'ridge', 'lasso', 'elasticnet',
        'random_forest', 'gradient_boosting', 'extra_trees'
    ])
    
    gradient_boosting_models: List[str] = field(default_factory=lambda: [
        'xgboost', 'lightgbm', 'catboost'
    ])
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
    cv_folds: int = 5
    time_series_split: bool = True
    shuffle_split: bool = False
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–±–æ—Ä–∞
    scoring_metric: Optional[str] = None
    top_k_models: int = 5
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
    max_training_time_per_model: int = 600  # —Å–µ–∫—É–Ω–¥
    min_score_threshold: Optional[float] = None


@dataclass
class EnsembleConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª–µ–π"""
    enable_voting: bool = True
    enable_stacking: bool = True
    enable_blending: bool = True
    enable_bagging: bool = False
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–æ–ª–æ—Å—É—é—â–µ–≥–æ –∞–Ω—Å–∞–º–±–ª—è
    voting_estimators_limit: int = 10
    voting_weights: Optional[List[float]] = None
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç–µ–∫–∏–Ω–≥–∞
    stacking_cv_folds: int = 5
    stacking_meta_learner: str = "ridge"  # ridge, linear_regression
    stacking_use_features_in_secondary: bool = True
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –±–ª–µ–Ω–¥–∏–Ω–≥–∞
    blending_holdout_size: float = 0.2
    
    # –û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    ensemble_size_limit: int = 5
    min_ensemble_diversity: float = 0.1


@dataclass
class DataPreprocessingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    missing_value_strategy: str = "median"  # mean, median, mode, drop, forward_fill
    missing_value_threshold: float = 0.5  # –ü–æ—Ä–æ–≥ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫/—Å—Ç—Ä–æ–∫
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤
    outlier_detection_method: str = "iqr"  # iqr, zscore, isolation_forest
    outlier_threshold: float = 3.0
    outlier_handling: str = "clip"  # clip, remove, transform
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
    scaling_method: str = "standard"  # standard, robust, minmax, quantile
    scale_target: bool = False
    
    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    categorical_encoding: str = "onehot"  # onehot, label, target, binary
    max_categories_onehot: int = 10
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
    handle_seasonality: bool = True
    detrend_method: Optional[str] = None  # linear, polynomial
    
    # –û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    random_state: int = 42
    n_jobs: int = -1


@dataclass
class ModelEvaluationConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π"""
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
    regression_metrics: List[str] = field(default_factory=lambda: [
        'mse', 'mae', 'r2', 'mape', 'rmse'
    ])
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    classification_metrics: List[str] = field(default_factory=lambda: [
        'accuracy', 'precision', 'recall', 'f1', 'auc'
    ])
    
    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    cv_folds: int = 5
    cv_scoring: Optional[str] = None
    
    # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    calculate_feature_importance: bool = True
    feature_importance_method: str = "permutation"  # permutation, shap, built_in
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    generate_plots: bool = True
    plot_format: str = "png"  # png, pdf, svg
    plot_dpi: int = 300
    
    # –û—Ç—á–µ—Ç—ã
    generate_report: bool = True
    report_format: str = "html"  # html, pdf, markdown


class AutoMLConfig(BaseSettings):
    """
    –ì–ª–∞–≤–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è AutoML Pipeline
    –†–µ–∞–ª–∏–∑—É–µ—Ç enterprise patterns –¥–ª—è configuration management
    """
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    project_name: str = Field(default="crypto_trading_automl", env="AUTOML_PROJECT_NAME")
    version: str = "1.0.0"
    random_state: int = Field(default=42, env="AUTOML_RANDOM_STATE")
    n_jobs: int = Field(default=-1, env="AUTOML_N_JOBS")
    
    # –ü—É—Ç–∏
    output_dir: str = Field(default="automl_output", env="AUTOML_OUTPUT_DIR")
    cache_dir: str = Field(default="automl_cache", env="AUTOML_CACHE_DIR")
    models_dir: str = Field(default="automl_models", env="AUTOML_MODELS_DIR")
    logs_dir: str = Field(default="automl_logs", env="AUTOML_LOGS_DIR")
    
    # –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã
    debug_mode: bool = Field(default=False, env="AUTOML_DEBUG")
    verbose: bool = Field(default=True, env="AUTOML_VERBOSE")
    enable_caching: bool = Field(default=True, env="AUTOML_CACHE")
    
    # –õ–∏–º–∏—Ç—ã —Ä–µ—Å—É—Ä—Å–æ–≤
    max_memory_gb: float = Field(default=8.0, env="AUTOML_MAX_MEMORY")
    max_training_time: int = Field(default=3600, env="AUTOML_MAX_TIME")  # —Å–µ–∫—É–Ω–¥
    max_models_to_try: int = Field(default=50, env="AUTOML_MAX_MODELS")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    feature_generation: FeatureGenerationConfig = field(default_factory=FeatureGenerationConfig)
    feature_selection: FeatureSelectionConfig = field(default_factory=FeatureSelectionConfig)
    hyperparameter_optimization: HyperparameterOptimizationConfig = field(
        default_factory=HyperparameterOptimizationConfig
    )
    model_selection: ModelSelectionConfig = field(default_factory=ModelSelectionConfig)
    ensemble: EnsembleConfig = field(default_factory=EnsembleConfig)
    data_preprocessing: DataPreprocessingConfig = field(default_factory=DataPreprocessingConfig)
    model_evaluation: ModelEvaluationConfig = field(default_factory=ModelEvaluationConfig)
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    crypto_specific: Dict[str, Any] = field(default_factory=lambda: {
        'enable_technical_indicators': True,
        'enable_market_regime_detection': True,
        'enable_volatility_features': True,
        'enable_momentum_features': True,
        'lookback_periods': [5, 10, 20, 50],
        'prediction_horizon': 1,  # –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–ø–µ—Ä–∏–æ–¥—ã)
        'risk_adjusted_metrics': True,
        'walk_forward_validation': True
    })
    
    class Config:
        env_file = ".env"
        env_file_encoding = 'utf-8'
        case_sensitive = False
    
    @validator('output_dir', 'cache_dir', 'models_dir', 'logs_dir')
    def create_directories(cls, v):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç"""
        Path(v).mkdir(parents=True, exist_ok=True)
        return v
    
    @validator('max_memory_gb')
    def validate_memory(cls, v):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ª–∏–º–∏—Ç–∞ –ø–∞–º—è—Ç–∏"""
        if v <= 0:
            raise ValueError("max_memory_gb –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º")
        return v
    
    @validator('n_jobs')
    def validate_n_jobs(cls, v):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤"""
        if v == 0:
            raise ValueError("n_jobs –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å 0")
        return v
    
    def save_to_file(self, filepath: Union[str, Path]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤ —Ñ–∞–π–ª"""
        filepath = Path(filepath)
        
        config_dict = self.dict()
        
        if filepath.suffix.lower() == '.json':
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(config_dict, f, indent=2, ensure_ascii=False)
        elif filepath.suffix.lower() in ['.yml', '.yaml']:
            with open(filepath, 'w', encoding='utf-8') as f:
                yaml.safe_dump(config_dict, f, default_flow_style=False)
        else:
            raise ValueError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∞—Ç—ã .json, .yml, .yaml")
        
        logger.info(f"üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filepath}")
    
    @classmethod
    def load_from_file(cls, filepath: Union[str, Path]):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        filepath = Path(filepath)
        
        if not filepath.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
        
        if filepath.suffix.lower() == '.json':
            with open(filepath, 'r', encoding='utf-8') as f:
                config_dict = json.load(f)
        elif filepath.suffix.lower() in ['.yml', '.yaml']:
            with open(filepath, 'r', encoding='utf-8') as f:
                config_dict = yaml.safe_load(f)
        else:
            raise ValueError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∞—Ç—ã .json, .yml, .yaml")
        
        logger.info(f"üìÇ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {filepath}")
        
        return cls(**config_dict)
    
    def get_model_config(self, model_name: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        model_configs = {
            'xgboost': {
                'random_state': self.random_state,
                'n_jobs': self.n_jobs,
                'verbosity': 0 if not self.verbose else 1
            },
            'lightgbm': {
                'random_state': self.random_state,
                'n_jobs': self.n_jobs,
                'verbose': -1 if not self.verbose else 1
            },
            'catboost': {
                'random_state': self.random_state,
                'verbose': self.verbose
            },
            'sklearn': {
                'random_state': self.random_state,
                'n_jobs': self.n_jobs if model_name in [
                    'random_forest', 'extra_trees', 'knn'
                ] else None
            }
        }
        
        # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è sklearn –º–æ–¥–µ–ª–µ–π
        base_config = model_configs.get('sklearn', {})
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if model_name.startswith('xgb') or model_name == 'xgboost':
            return {**base_config, **model_configs['xgboost']}
        elif model_name.startswith('lgb') or model_name == 'lightgbm':
            return {**base_config, **model_configs['lightgbm']}
        elif model_name.startswith('cat') or model_name == 'catboost':
            return {**base_config, **model_configs['catboost']}
        else:
            return base_config
    
    def get_crypto_features_config(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        return {
            **self.crypto_specific,
            'technical_windows': self.feature_generation.technical_indicators_windows,
            'statistical_windows': self.feature_generation.statistical_windows,
            'enable_technical': self.feature_generation.enable_technical_indicators,
            'enable_statistical': self.feature_generation.enable_statistical_features
        }
    
    def get_validation_config(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        return {
            'cv_folds': self.model_selection.cv_folds,
            'time_series_split': self.model_selection.time_series_split,
            'walk_forward_validation': self.crypto_specific.get('walk_forward_validation', True),
            'random_state': self.random_state
        }
    
    def __str__(self) -> str:
        """–°—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        return f"AutoMLConfig(project='{self.project_name}', version='{self.version}')"


# –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
class PresetConfigs:
    """–ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤"""
    
    @staticmethod
    def fast_prototype() -> AutoMLConfig:
        """–ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è"""
        config = AutoMLConfig()
        
        # –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
        config.hyperparameter_optimization.n_trials = 20
        config.model_selection.cv_folds = 3
        config.model_evaluation.cv_folds = 3
        
        # –û—Ç–∫–ª—é—á–∞–µ–º —Å–ª–æ–∂–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        config.feature_generation.enable_tsfresh_features = False
        config.feature_generation.enable_polynomial_features = False
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏
        config.model_selection.sklearn_models = ['ridge', 'random_forest']
        config.model_selection.gradient_boosting_models = ['xgboost']
        
        return config
    
    @staticmethod
    def production_ready() -> AutoMLConfig:
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞"""
        config = AutoMLConfig()
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
        config.hyperparameter_optimization.n_trials = 200
        config.model_selection.cv_folds = 10
        config.model_evaluation.cv_folds = 10
        
        # –í–∫–ª—é—á–∞–µ–º –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏
        config.feature_generation.enable_tsfresh_features = True
        config.feature_generation.enable_polynomial_features = True
        
        # –í–∫–ª—é—á–∞–µ–º –∞–Ω—Å–∞–º–±–ª–∏
        config.ensemble.enable_stacking = True
        config.ensemble.enable_voting = True
        
        # –í–∫–ª—é—á–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—É—é –æ—Ü–µ–Ω–∫—É
        config.model_evaluation.calculate_feature_importance = True
        config.model_evaluation.generate_plots = True
        config.model_evaluation.generate_report = True
        
        return config
    
    @staticmethod
    def crypto_trading() -> AutoMLConfig:
        """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–∞"""
        config = AutoMLConfig()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã
        config.model_selection.time_series_split = True
        config.data_preprocessing.handle_seasonality = True
        
        # –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        config.feature_generation.enable_technical_indicators = True
        config.feature_generation.technical_indicators_windows = [5, 10, 20, 50, 100]
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        config.crypto_specific.update({
            'enable_volatility_features': True,
            'enable_momentum_features': True,
            'enable_market_regime_detection': True,
            'lookback_periods': [1, 3, 5, 10, 20],
            'prediction_horizon': 1
        })
        
        # –ú–æ–¥–µ–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
        config.model_selection.sklearn_models = [
            'ridge', 'lasso', 'elasticnet', 'random_forest', 'gradient_boosting'
        ]
        config.model_selection.gradient_boosting_models = ['xgboost', 'lightgbm']
        
        return config
    
    @staticmethod
    def high_frequency_trading() -> AutoMLConfig:
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –≤—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–æ–≥–æ —Ç—Ä–µ–π–¥–∏–Ω–≥–∞"""
        config = PresetConfigs.crypto_trading()
        
        # –°–æ–∫—Ä–∞—â–∞–µ–º –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
        config.max_training_time = 1800  # 30 –º–∏–Ω—É—Ç
        config.hyperparameter_optimization.n_trials = 50
        config.hyperparameter_optimization.timeout_per_trial = 60
        
        # –ë—ã—Å—Ç—Ä—ã–µ –º–æ–¥–µ–ª–∏
        config.model_selection.sklearn_models = ['ridge', 'lasso']
        config.model_selection.gradient_boosting_models = ['lightgbm']  # –°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π
        
        # –û—Ç–∫–ª—é—á–∞–µ–º —Å–ª–æ–∂–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        config.feature_generation.enable_tsfresh_features = False
        config.feature_generation.polynomial_max_features = 20
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è HFT
        config.crypto_specific.update({
            'lookback_periods': [1, 2, 3, 5],  # –ö–æ—Ä–æ—Ç–∫–∏–µ –ø–µ—Ä–∏–æ–¥—ã
            'prediction_horizon': 1,  # –¢–æ–ª—å–∫–æ —Å–ª–µ–¥—É—é—â–∏–π —Ç–∏–∫
            'enable_microstructure_features': True,
            'enable_order_book_features': True
        })
        
        return config


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = AutoMLConfig()
    print(f"–ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {config}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
    config.save_to_file("automl_config.json")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ —Ñ–∞–π–ª–∞
    loaded_config = AutoMLConfig.load_from_file("automl_config.json")
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {loaded_config}")
    
    # –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    fast_config = PresetConfigs.fast_prototype()
    print(f"–ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {fast_config}")
    
    crypto_config = PresetConfigs.crypto_trading()
    print(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–∞: {crypto_config}")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
    xgb_config = config.get_model_config('xgboost')
    print(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è XGBoost: {xgb_config}")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    validation_config = config.get_validation_config()
    print(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {validation_config}")