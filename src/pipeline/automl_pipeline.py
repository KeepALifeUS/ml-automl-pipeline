"""
Main AutoML Pipeline for Crypto Trading Bot v5.0
Orchestrates the complete machine learning workflow with Context7 enterprise patterns
"""

import logging
from typing import Dict, List, Optional, Tuple, Union, Any, Callable
from dataclasses import dataclass
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score
from sklearn.preprocessing import StandardScaler, RobustScaler
import joblib
import pickle
import json
import time
from pathlib import Path
from loguru import logger
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeRemainingColumn
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
import matplotlib.pyplot as plt
import seaborn as sns

from ..feature_engineering.auto_feature_generator import AutoFeatureGenerator, FeatureGenerationResult
from ..feature_engineering.feature_selector import AdvancedFeatureSelector, FeatureSelectionResult
from ..optimization.bayesian_optimizer import CryptoMLHyperparameterOptimizer, OptimizationResult
from ..model_selection.model_selector import ModelSelector, ModelSelectionResult
from ..model_selection.ensemble_builder import EnsembleBuilder, EnsembleResult
from ..evaluation.model_evaluator import ModelEvaluator, EvaluationResult
from ..utils.config_manager import AutoMLConfig
from ..utils.data_preprocessor import DataPreprocessor


class PipelineStage(Enum):
    """–≠—Ç–∞–ø—ã AutoML –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    DATA_PREPROCESSING = "data_preprocessing"
    FEATURE_GENERATION = "feature_generation"
    FEATURE_SELECTION = "feature_selection"
    MODEL_SELECTION = "model_selection"
    HYPERPARAMETER_OPTIMIZATION = "hyperparameter_optimization"
    ENSEMBLE_BUILDING = "ensemble_building"
    MODEL_EVALUATION = "model_evaluation"
    MODEL_DEPLOYMENT = "model_deployment"


@dataclass
class PipelineResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è AutoML –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    best_model: Any
    best_model_name: str
    best_score: float
    feature_generation_result: Optional[FeatureGenerationResult]
    feature_selection_result: Optional[FeatureSelectionResult]
    optimization_results: Dict[str, OptimizationResult]
    ensemble_result: Optional[EnsembleResult]
    evaluation_result: EvaluationResult
    pipeline_metadata: Dict[str, Any]
    total_time: float
    stages_completed: List[str]


class AutoMLPipeline:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å AutoML –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –∫—Ä–∏–ø—Ç–æ—Ç—Ä–µ–π–¥–∏–Ω–≥–∞
    –†–µ–∞–ª–∏–∑—É–µ—Ç Context7 enterprise patterns –¥–ª—è scalable ML systems
    """
    
    def __init__(self, config: Optional[AutoMLConfig] = None, output_dir: Optional[str] = None):
        self.config = config or AutoMLConfig()
        self.output_dir = Path(output_dir or "automl_output")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.preprocessor = DataPreprocessor(self.config)
        self.feature_generator = AutoFeatureGenerator(self.config)
        self.feature_selector = AdvancedFeatureSelector(self.config)
        self.hyperparameter_optimizer = CryptoMLHyperparameterOptimizer(self.config)
        self.model_selector = ModelSelector(self.config)
        self.ensemble_builder = EnsembleBuilder(self.config)
        self.evaluator = ModelEvaluator(self.config)
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞
        self.pipeline_state = {}
        self.console = Console()
        
        logger.info("üöÄ AutoML Pipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def run(
        self,
        data: pd.DataFrame,
        target_column: str,
        test_size: float = 0.2,
        validation_size: float = 0.2,
        time_series_split: bool = True,
        stages: Optional[List[str]] = None
    ) -> PipelineResult:
        """
        –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ AutoML –ø–∞–π–ø–ª–∞–π–Ω–∞
        
        Args:
            data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            target_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            test_size: –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏
            validation_size: –†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
            time_series_split: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è
            stages: –°–ø–∏—Å–æ–∫ —ç—Ç–∞–ø–æ–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ)
        """
        start_time = time.time()
        
        self.console.print(
            Panel.fit(
                "ü§ñ [bold blue]CRYPTO TRADING AUTOML PIPELINE v5.0[/bold blue] üöÄ\n"
                f"üìä –î–∞–Ω–Ω—ã—Ö: {len(data)} –∑–∞–ø–∏—Å–µ–π, {len(data.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n"
                f"üéØ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {target_column}",
                title="–ó–∞–ø—É—Å–∫ AutoML Pipeline"
            )
        )
        
        if stages is None:
            stages = [stage.value for stage in PipelineStage]
        
        stages_completed = []
        pipeline_metadata = {
            'start_time': start_time,
            'data_shape': data.shape,
            'target_column': target_column,
            'config': self.config.dict() if hasattr(self.config, 'dict') else str(self.config)
        }
        
        try:
            # === –≠–¢–ê–ü 1: –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• ===
            if PipelineStage.DATA_PREPROCESSING.value in stages:
                logger.info("üîß –≠—Ç–∞–ø 1: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
                
                X, y = self._preprocess_data(data, target_column)
                X_train, X_test, y_train, y_test = self._split_data(
                    X, y, test_size, validation_size, time_series_split
                )
                
                stages_completed.append(PipelineStage.DATA_PREPROCESSING.value)
                
                self.console.print("‚úÖ [green]–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞[/green]")
            else:
                logger.info("‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
                X = data.drop(columns=[target_column])
                y = data[target_column]
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size, random_state=42
                )
            
            # === –≠–¢–ê–ü 2: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í ===
            feature_generation_result = None
            if PipelineStage.FEATURE_GENERATION.value in stages:
                logger.info("üé® –≠—Ç–∞–ø 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                
                feature_generation_result = self._generate_features(X_train)
                
                if feature_generation_result and not feature_generation_result.features.empty:
                    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ
                    X_train_enhanced = pd.concat([X_train, feature_generation_result.features], axis=1)
                    
                    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
                    test_features = self.feature_generator.generate_features(X_test)
                    X_test_enhanced = pd.concat([X_test, test_features.features], axis=1)
                    
                    X_train = X_train_enhanced
                    X_test = X_test_enhanced
                
                stages_completed.append(PipelineStage.FEATURE_GENERATION.value)
                self.console.print("‚úÖ [green]–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞[/green]")
            
            # === –≠–¢–ê–ü 3: –û–¢–ë–û–† –ü–†–ò–ó–ù–ê–ö–û–í ===
            feature_selection_result = None
            if PipelineStage.FEATURE_SELECTION.value in stages:
                logger.info("üéØ –≠—Ç–∞–ø 3: –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                
                feature_selection_result = self._select_features(X_train, y_train)
                
                if feature_selection_result and feature_selection_result.selected_features:
                    X_train = X_train[feature_selection_result.selected_features]
                    X_test = X_test[feature_selection_result.selected_features]
                
                stages_completed.append(PipelineStage.FEATURE_SELECTION.value)
                self.console.print("‚úÖ [green]–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω[/green]")
            
            # === –≠–¢–ê–ü 4: –û–¢–ë–û–† –ú–û–î–ï–õ–ï–ô ===
            model_selection_result = None
            if PipelineStage.MODEL_SELECTION.value in stages:
                logger.info("ü§ñ –≠—Ç–∞–ø 4: –û—Ç–±–æ—Ä –º–æ–¥–µ–ª–µ–π")
                
                model_selection_result = self._select_models(X_train, y_train)
                
                stages_completed.append(PipelineStage.MODEL_SELECTION.value)
                self.console.print("‚úÖ [green]–û—Ç–±–æ—Ä –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω[/green]")
            
            # === –≠–¢–ê–ü 5: –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í ===
            optimization_results = {}
            if PipelineStage.HYPERPARAMETER_OPTIMIZATION.value in stages:
                logger.info("‚öôÔ∏è –≠—Ç–∞–ø 5: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
                
                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                models_to_optimize = []
                if model_selection_result:
                    # –ë–µ—Ä–µ–º —Ç–æ–ø-3 –º–æ–¥–µ–ª–∏
                    sorted_models = sorted(
                        model_selection_result.model_scores.items(),
                        key=lambda x: x[1],
                        reverse=True
                    )
                    models_to_optimize = [model[0] for model in sorted_models[:3]]
                else:
                    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
                    models_to_optimize = ['xgboost', 'random_forest', 'lightgbm']
                
                optimization_results = self._optimize_hyperparameters(
                    X_train, y_train, models_to_optimize
                )
                
                stages_completed.append(PipelineStage.HYPERPARAMETER_OPTIMIZATION.value)
                self.console.print("‚úÖ [green]–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞[/green]")
            
            # === –≠–¢–ê–ü 6: –ü–û–°–¢–†–û–ï–ù–ò–ï –ê–ù–°–ê–ú–ë–õ–Ø ===
            ensemble_result = None
            if PipelineStage.ENSEMBLE_BUILDING.value in stages:
                logger.info("ü§ù –≠—Ç–∞–ø 6: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è")
                
                ensemble_result = self._build_ensemble(
                    X_train, y_train, optimization_results
                )
                
                stages_completed.append(PipelineStage.ENSEMBLE_BUILDING.value)
                self.console.print("‚úÖ [green]–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ[/green]")
            
            # === –≠–¢–ê–ü 7: –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ï–ô ===
            evaluation_result = None
            if PipelineStage.MODEL_EVALUATION.value in stages:
                logger.info("üìä –≠—Ç–∞–ø 7: –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π")
                
                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                best_model, best_model_name, best_score = self._select_best_model(
                    optimization_results, ensemble_result
                )
                
                evaluation_result = self._evaluate_models(
                    X_train, y_train, X_test, y_test,
                    best_model, best_model_name
                )
                
                stages_completed.append(PipelineStage.MODEL_EVALUATION.value)
                self.console.print("‚úÖ [green]–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞[/green]")
            
            # === –°–û–ó–î–ê–ù–ò–ï –ò–¢–û–ì–û–í–û–ì–û –†–ï–ó–£–õ–¨–¢–ê–¢–ê ===
            total_time = time.time() - start_time
            pipeline_metadata.update({
                'end_time': time.time(),
                'stages_completed': stages_completed,
                'final_features_count': X_train.shape[1] if 'X_train' in locals() else 0
            })
            
            result = PipelineResult(
                best_model=best_model if 'best_model' in locals() else None,
                best_model_name=best_model_name if 'best_model_name' in locals() else "unknown",
                best_score=best_score if 'best_score' in locals() else 0.0,
                feature_generation_result=feature_generation_result,
                feature_selection_result=feature_selection_result,
                optimization_results=optimization_results,
                ensemble_result=ensemble_result,
                evaluation_result=evaluation_result,
                pipeline_metadata=pipeline_metadata,
                total_time=total_time,
                stages_completed=stages_completed
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self._save_pipeline_results(result)
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
            self._print_final_report(result)
            
            logger.info(f"üéâ AutoML Pipeline –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {total_time:.2f}—Å")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ AutoML Pipeline: {e}")
            raise
    
    def _preprocess_data(self, data: pd.DataFrame, target_column: str) -> Tuple[pd.DataFrame, pd.Series]:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("üîß –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        X = data.drop(columns=[target_column])
        y = data[target_column]
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø–æ–º–æ—â—å—é DataPreprocessor
        X_processed = self.preprocessor.preprocess(X)
        y_processed = self.preprocessor.preprocess_target(y)
        
        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {X_processed.shape[0]} –∑–∞–ø–∏—Å–µ–π, {X_processed.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        return X_processed, y_processed
    
    def _split_data(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        test_size: float,
        validation_size: float,
        time_series_split: bool
    ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏"""
        logger.info("‚úÇÔ∏è –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
        
        if time_series_split:
            # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ (–±–µ–∑ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏—è)
            split_idx = int(len(X) * (1 - test_size))
            X_train = X.iloc[:split_idx]
            X_test = X.iloc[split_idx:]
            y_train = y.iloc[:split_idx]
            y_test = y.iloc[split_idx:]
        else:
            # –°–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )
        
        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã: –æ–±—É—á–µ–Ω–∏–µ={len(X_train)}, —Ç–µ—Å—Ç={len(X_test)}")
        
        return X_train, X_test, y_train, y_test
    
    def _generate_features(self, X: pd.DataFrame) -> Optional[FeatureGenerationResult]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        try:
            result = self.feature_generator.generate_features(X, parallel=True)
            
            logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(result.feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return None
    
    def _select_features(
        self,
        X: pd.DataFrame,
        y: pd.Series
    ) -> Optional[FeatureSelectionResult]:
        """–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üéØ –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        try:
            result = self.feature_selector.select_features(
                X, y,
                ensemble_selection=True
            )
            
            logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(result.selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return None
    
    def _select_models(self, X: pd.DataFrame, y: pd.Series) -> Optional[ModelSelectionResult]:
        """–û—Ç–±–æ—Ä –º–æ–¥–µ–ª–µ–π"""
        logger.info("ü§ñ –û—Ç–±–æ—Ä –º–æ–¥–µ–ª–µ–π...")
        
        try:
            result = self.model_selector.select_best_models(
                X, y,
                models=['xgboost', 'random_forest', 'lightgbm', 'ridge', 'elasticnet'],
                cv_folds=3  # –ú–µ–Ω—å—à–µ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            )
            
            logger.info(f"‚úÖ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(result.model_scores)} –º–æ–¥–µ–ª–µ–π")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π: {e}")
            return None
    
    def _optimize_hyperparameters(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        models: List[str]
    ) -> Dict[str, OptimizationResult]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        logger.info(f"‚öôÔ∏è –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è {len(models)} –º–æ–¥–µ–ª–µ–π...")
        
        try:
            results = self.hyperparameter_optimizer.optimize_multiple_models(
                X, y,
                models=models,
                optimizer_method='optuna_tpe',
                n_calls=50  # –ú–µ–Ω—å—à–µ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            )
            
            logger.info(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è {len(results)} –º–æ–¥–µ–ª–µ–π")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
            return {}
    
    def _build_ensemble(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        optimization_results: Dict[str, OptimizationResult]
    ) -> Optional[EnsembleResult]:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è"""
        logger.info("ü§ù –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è...")
        
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            models = {}
            for model_name, result in optimization_results.items():
                model = self.hyperparameter_optimizer._get_model(model_name, result.best_params)
                models[model_name] = model
            
            if not models:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è")
                return None
            
            result = self.ensemble_builder.build_ensemble(
                X, y,
                models,
                ensemble_methods=['voting', 'stacking']
            )
            
            logger.info(f"‚úÖ –ê–Ω—Å–∞–º–±–ª—å –ø–æ—Å—Ç—Ä–æ–µ–Ω —Å {len(models)} –º–æ–¥–µ–ª—è–º–∏")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è: {e}")
            return None
    
    def _select_best_model(
        self,
        optimization_results: Dict[str, OptimizationResult],
        ensemble_result: Optional[EnsembleResult]
    ) -> Tuple[Any, str, float]:
        """–í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏"""
        logger.info("üèÜ –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏...")
        
        best_model = None
        best_model_name = "unknown"
        best_score = float('inf')
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        for model_name, result in optimization_results.items():
            if result.best_score < best_score:
                best_score = result.best_score
                best_model_name = model_name
                best_model = self.hyperparameter_optimizer._get_model(
                    model_name, result.best_params
                )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω—Å–∞–º–±–ª—è
        if ensemble_result and ensemble_result.best_ensemble_score < best_score:
            best_score = ensemble_result.best_ensemble_score
            best_model_name = f"ensemble_{ensemble_result.best_ensemble_method}"
            best_model = ensemble_result.ensembles[ensemble_result.best_ensemble_method]
        
        logger.info(f"‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name} (—Å–∫–æ—Ä: {abs(best_score):.4f})")
        
        return best_model, best_model_name, best_score
    
    def _evaluate_models(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_test: pd.DataFrame,
        y_test: pd.Series,
        best_model: Any,
        best_model_name: str
    ) -> EvaluationResult:
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π"""
        logger.info("üìä –û—Ü–µ–Ω–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏...")
        
        try:
            # –û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            best_model.fit(X_train, y_train)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred_train = best_model.predict(X_train)
            y_pred_test = best_model.predict(X_test)
            
            result = self.evaluator.evaluate_model(
                best_model,
                X_train, y_train,
                X_test, y_test,
                model_name=best_model_name
            )
            
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –æ—Ü–µ–Ω–µ–Ω–∞: R¬≤ = {result.test_r2:.4f}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return EvaluationResult(
                model_name=best_model_name,
                train_mse=0.0, train_mae=0.0, train_r2=0.0,
                test_mse=0.0, test_mae=0.0, test_r2=0.0,
                cross_val_scores=[], feature_importance={},
                evaluation_metadata={}, evaluation_time=0.0
            )
    
    def _save_pipeline_results(self, result: PipelineResult):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        
        try:
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            if result.best_model:
                model_path = self.output_dir / "best_model.pkl"
                joblib.dump(result.best_model, model_path)
                logger.info(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            metadata_path = self.output_dir / "pipeline_metadata.json"
            with open(metadata_path, 'w') as f:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ serializable —Ñ–æ—Ä–º–∞—Ç
                serializable_metadata = {
                    'best_model_name': result.best_model_name,
                    'best_score': result.best_score,
                    'total_time': result.total_time,
                    'stages_completed': result.stages_completed,
                    'pipeline_metadata': result.pipeline_metadata
                }
                json.dump(serializable_metadata, f, indent=2)
            
            logger.info(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
    
    def _print_final_report(self, result: PipelineResult):
        """–í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        table = Table(title="üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ AUTOML PIPELINE")
        
        table.add_column("–ú–µ—Ç—Ä–∏–∫–∞", style="cyan", no_wrap=True)
        table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="magenta")
        
        table.add_row("üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å", result.best_model_name)
        table.add_row("üìä –õ—É—á—à–∏–π —Å–∫–æ—Ä", f"{abs(result.best_score):.4f}")
        table.add_row("‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", f"{result.total_time:.2f}—Å")
        table.add_row("üéØ –≠—Ç–∞–ø–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ", f"{len(result.stages_completed)}/8")
        
        if result.feature_generation_result:
            table.add_row("üé® –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ", str(len(result.feature_generation_result.feature_names)))
        
        if result.feature_selection_result:
            table.add_row("üîç –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ—Ç–æ–±—Ä–∞–Ω–æ", str(len(result.feature_selection_result.selected_features)))
        
        if result.optimization_results:
            table.add_row("‚öôÔ∏è –ú–æ–¥–µ–ª–µ–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ", str(len(result.optimization_results)))
        
        if result.evaluation_result:
            table.add_row("üìà R¬≤ –Ω–∞ —Ç–µ—Å—Ç–µ", f"{result.evaluation_result.test_r2:.4f}")
            table.add_row("üìâ MSE –Ω–∞ —Ç–µ—Å—Ç–µ", f"{result.evaluation_result.test_mse:.4f}")
        
        self.console.print(table)
        
        # –î–µ—Ç–∞–ª–∏ —ç—Ç–∞–ø–æ–≤
        stages_panel = Panel(
            " ‚Üí ".join(result.stages_completed),
            title="üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã"
        )
        self.console.print(stages_panel)


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è AutoML Pipeline
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–∏–º–∏—Ç–∞—Ü–∏—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', periods=2000, freq='1H')
    
    # –ë–∞–∑–æ–≤—ã–µ OHLCV –¥–∞–Ω–Ω—ã–µ
    data = pd.DataFrame({
        'open': np.random.randn(2000).cumsum() + 50000,
        'high': np.random.randn(2000).cumsum() + 50100,
        'low': np.random.randn(2000).cumsum() + 49900,
        'close': np.random.randn(2000).cumsum() + 50000,
        'volume': np.random.exponential(1000, 2000)
    }, index=dates)
    
    # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (–±—É–¥—É—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å)
    data['future_return'] = data['close'].shift(-1) / data['close'] - 1
    data = data.dropna()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞
    config = AutoMLConfig()
    pipeline = AutoMLPipeline(config, output_dir="test_automl_output")
    
    result = pipeline.run(
        data=data,
        target_column='future_return',
        test_size=0.2,
        time_series_split=True
    )
    
    print(f"\nüéâ AutoML Pipeline –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {result.best_model_name}")
    print(f"üìä –õ—É—á—à–∏–π —Å–∫–æ—Ä: {abs(result.best_score):.4f}")
    print(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result.total_time:.2f}—Å")