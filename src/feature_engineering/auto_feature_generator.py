"""
Automated Feature Generator for Crypto Trading AutoML Pipeline
Implements enterprise patterns for scalable feature generation
"""

import logging
from typing import Dict, List, Optional, Tuple, Union, Any
from dataclasses import dataclass
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression
import ta
import pandas_ta as pta
from tsfresh import extract_features, extract_relevant_features
from tsfresh.utilities.dataframe_functions import impute
from featuretools import dfs
import feature_engine.creation as fec
from loguru import logger
from pydantic import BaseModel, Field
from rich.progress import Progress, SpinnerColumn, TextColumn
from joblib import Parallel, delayed

from ..utils.config_manager import AutoMLConfig
from ..utils.data_preprocessor import DataPreprocessor


@dataclass
class FeatureGenerationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    features: pd.DataFrame
    feature_names: List[str]
    feature_importance: Dict[str, float]
    generation_metadata: Dict[str, Any]
    processing_time: float


class BaseFeatureGenerator(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ -  pattern"""
    
    @abstractmethod
    def generate(self, data: pd.DataFrame) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏"""
        pass
    
    @abstractmethod
    def get_feature_names(self) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–º–µ–Ω–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        pass


class TechnicalIndicatorGenerator(BaseFeatureGenerator):
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.feature_names = []
        
    def generate(self, data: pd.DataFrame) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        logger.info("üîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤...")
        
        features = pd.DataFrame(index=data.index)
        
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        required_cols = ['open', 'high', 'low', 'close', 'volume']
        if not all(col in data.columns for col in required_cols):
            logger.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
            return features
        
        try:
            # –û—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Ç—Ä–µ–Ω–¥–∞
            features['sma_10'] = ta.trend.sma_indicator(data['close'], window=10)
            features['sma_20'] = ta.trend.sma_indicator(data['close'], window=20)
            features['sma_50'] = ta.trend.sma_indicator(data['close'], window=50)
            features['ema_12'] = ta.trend.ema_indicator(data['close'], window=12)
            features['ema_26'] = ta.trend.ema_indicator(data['close'], window=26)
            
            # MACD
            features['macd'] = ta.trend.macd(data['close'])
            features['macd_signal'] = ta.trend.macd_signal(data['close'])
            features['macd_histogram'] = ta.trend.macd_diff(data['close'])
            
            # Bollinger Bands
            bb_high = ta.volatility.bollinger_hband(data['close'])
            bb_low = ta.volatility.bollinger_lband(data['close'])
            features['bb_high'] = bb_high
            features['bb_low'] = bb_low
            features['bb_width'] = bb_high - bb_low
            features['bb_position'] = (data['close'] - bb_low) / (bb_high - bb_low)
            
            # RSI
            features['rsi'] = ta.momentum.rsi(data['close'])
            features['rsi_oversold'] = (features['rsi'] < 30).astype(int)
            features['rsi_overbought'] = (features['rsi'] > 70).astype(int)
            
            # Stochastic
            features['stoch_k'] = ta.momentum.stoch(data['high'], data['low'], data['close'])
            features['stoch_d'] = ta.momentum.stoch_signal(data['high'], data['low'], data['close'])
            
            # Volume indicators
            features['volume_sma'] = ta.volume.volume_sma(data['close'], data['volume'])
            features['vwap'] = ta.volume.volume_weighted_average_price(
                data['high'], data['low'], data['close'], data['volume']
            )
            
            # ATR - Average True Range
            features['atr'] = ta.volatility.average_true_range(data['high'], data['low'], data['close'])
            
            # –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            features['price_change_1h'] = data['close'].pct_change(periods=1)
            features['price_change_4h'] = data['close'].pct_change(periods=4)
            features['price_change_24h'] = data['close'].pct_change(periods=24)
            
            # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            features['volatility_10'] = data['close'].rolling(10).std()
            features['volatility_20'] = data['close'].rolling(20).std()
            
            # Momentum features
            features['momentum_5'] = ta.momentum.roc(data['close'], window=5)
            features['momentum_10'] = ta.momentum.roc(data['close'], window=10)
            
            self.feature_names = list(features.columns)
            logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(self.feature_names)} —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤")
            
            return features.fillna(0)  # –ó–∞–ø–æ–ª–Ω–∏—Ç—å NaN –Ω—É–ª—è–º–∏
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {e}")
            return features
    
    def get_feature_names(self) -> List[str]:
        return self.feature_names


class StatisticalFeatureGenerator(BaseFeatureGenerator):
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    
    def __init__(self, windows: List[int] = [5, 10, 20, 50]):
        self.windows = windows
        self.feature_names = []
    
    def generate(self, data: pd.DataFrame) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        features = pd.DataFrame(index=data.index)
        
        if 'close' not in data.columns:
            logger.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ 'close' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return features
        
        try:
            close = data['close']
            
            for window in self.windows:
                # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                features[f'mean_{window}'] = close.rolling(window).mean()
                features[f'std_{window}'] = close.rolling(window).std()
                features[f'min_{window}'] = close.rolling(window).min()
                features[f'max_{window}'] = close.rolling(window).max()
                features[f'median_{window}'] = close.rolling(window).median()
                
                # –ö–≤–∞–Ω—Ç–∏–ª–∏
                features[f'q25_{window}'] = close.rolling(window).quantile(0.25)
                features[f'q75_{window}'] = close.rolling(window).quantile(0.75)
                
                # –ê—Å–∏–º–º–µ—Ç—Ä–∏—è –∏ —ç–∫—Å—Ü–µ—Å—Å
                features[f'skew_{window}'] = close.rolling(window).skew()
                features[f'kurtosis_{window}'] = close.rolling(window).kurt()
                
                # Z-score
                rolling_mean = close.rolling(window).mean()
                rolling_std = close.rolling(window).std()
                features[f'zscore_{window}'] = (close - rolling_mean) / rolling_std
                
                # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
                rolling_min = close.rolling(window).min()
                rolling_max = close.rolling(window).max()
                features[f'position_{window}'] = (close - rolling_min) / (rolling_max - rolling_min)
            
            # –õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            for lag in [1, 2, 3, 5, 10]:
                features[f'lag_{lag}'] = close.shift(lag)
                features[f'diff_{lag}'] = close.diff(lag)
                features[f'pct_change_{lag}'] = close.pct_change(lag)
            
            self.feature_names = list(features.columns)
            logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(self.feature_names)} —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            return features.fillna(method='ffill').fillna(0)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return features
    
    def get_feature_names(self) -> List[str]:
        return self.feature_names


class PolynomialFeatureGenerator(BaseFeatureGenerator):
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    
    def __init__(self, degree: int = 2, interaction_only: bool = True, max_features: int = 100):
        self.degree = degree
        self.interaction_only = interaction_only
        self.max_features = max_features
        self.poly_transformer = None
        self.feature_names = []
    
    def generate(self, data: pd.DataFrame) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üî¢ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        if data.empty:
            return pd.DataFrame(index=data.index)
        
        try:
            # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            numeric_data = data.select_dtypes(include=[np.number]).fillna(0)
            
            if numeric_data.shape[1] > 20:
                # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–æ–ª–æ–Ω–æ–∫, –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-20 –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
                correlations = numeric_data.corrwith(numeric_data.iloc[:, 0]).abs()
                top_features = correlations.nlargest(20).index
                numeric_data = numeric_data[top_features]
            
            self.poly_transformer = PolynomialFeatures(
                degree=self.degree,
                interaction_only=self.interaction_only,
                include_bias=False
            )
            
            poly_features = self.poly_transformer.fit_transform(numeric_data)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if poly_features.shape[1] > self.max_features:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º SelectKBest –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                if len(numeric_data) > 1:
                    target = numeric_data.iloc[:, 0]  # –ü–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ –∫–∞–∫ —Ü–µ–ª–µ–≤–∞—è
                    selector = SelectKBest(f_regression, k=self.max_features)
                    poly_features = selector.fit_transform(poly_features, target)
                else:
                    poly_features = poly_features[:, :self.max_features]
            
            feature_names = [f'poly_{i}' for i in range(poly_features.shape[1])]
            features = pd.DataFrame(poly_features, index=data.index, columns=feature_names)
            
            self.feature_names = feature_names
            logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(feature_names)} –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            return features
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return pd.DataFrame(index=data.index)
    
    def get_feature_names(self) -> List[str]:
        return self.feature_names


class TSFreshFeatureGenerator(BaseFeatureGenerator):
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å TSFresh"""
    
    def __init__(self, max_features: int = 50):
        self.max_features = max_features
        self.feature_names = []
    
    def generate(self, data: pd.DataFrame) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("‚è∞ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ TSFresh...")
        
        if data.empty or len(data) < 10:
            return pd.DataFrame(index=data.index)
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è TSFresh
            time_series_data = data.copy()
            time_series_data['id'] = 1
            time_series_data['time'] = range(len(data))
            
            # –í—ã–±–∏—Ä–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
            if not numeric_cols:
                return pd.DataFrame(index=data.index)
            
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —á–∏—Å–ª–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            value_col = numeric_cols[0]
            ts_data = time_series_data[['id', 'time', value_col]].copy()
            ts_data.columns = ['id', 'time', 'value']
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            extracted_features = extract_features(
                ts_data,
                column_id='id',
                column_sort='time',
                column_value='value',
                n_jobs=1,
                disable_progressbar=True
            )
            
            # –ò–º–ø—É—Ç–∞—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            imputed_features = impute(extracted_features)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if imputed_features.shape[1] > self.max_features:
                # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
                feature_vars = imputed_features.var()
                top_features = feature_vars.nlargest(self.max_features).index
                imputed_features = imputed_features[top_features]
            
            # –¢—Ä–∞–Ω—Å–ª–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞ –≤–µ—Å—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥
            features = pd.DataFrame(index=data.index)
            for col in imputed_features.columns:
                features[f'tsfresh_{col}'] = imputed_features[col].iloc[0]
            
            self.feature_names = list(features.columns)
            logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(self.feature_names)} TSFresh –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            return features.fillna(0)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ TSFresh –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return pd.DataFrame(index=data.index)
    
    def get_feature_names(self) -> List[str]:
        return self.feature_names


class AutoFeatureGenerator:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    –†–µ–∞–ª–∏–∑—É–µ—Ç enterprise patterns
    """
    
    def __init__(self, config: Optional[AutoMLConfig] = None):
        self.config = config or AutoMLConfig()
        self.generators: Dict[str, BaseFeatureGenerator] = {}
        self.feature_metadata: Dict[str, Any] = {}
        self._setup_generators()
        
    def _setup_generators(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        logger.info("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        self.generators['technical'] = TechnicalIndicatorGenerator(
            self.config.feature_generation.get('technical', {})
        )
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        self.generators['statistical'] = StatisticalFeatureGenerator(
            windows=self.config.feature_generation.get('statistical_windows', [5, 10, 20])
        )
        
        # –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if self.config.feature_generation.get('enable_polynomial', True):
            self.generators['polynomial'] = PolynomialFeatureGenerator(
                degree=self.config.feature_generation.get('polynomial_degree', 2),
                max_features=self.config.feature_generation.get('polynomial_max_features', 50)
            )
        
        # TSFresh –ø—Ä–∏–∑–Ω–∞–∫–∏
        if self.config.feature_generation.get('enable_tsfresh', True):
            self.generators['tsfresh'] = TSFreshFeatureGenerator(
                max_features=self.config.feature_generation.get('tsfresh_max_features', 30)
            )
        
        logger.info(f"‚úÖ –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ {len(self.generators)} –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤")
    
    def generate_features(
        self,
        data: pd.DataFrame,
        generators: Optional[List[str]] = None,
        parallel: bool = True
    ) -> FeatureGenerationResult:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Args:
            data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            generators: –°–ø–∏—Å–æ–∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            parallel: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
            
        Returns:
            FeatureGenerationResult: –†–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        import time
        start_time = time.time()
        
        if generators is None:
            generators = list(self.generators.keys())
        
        all_features = []
        all_feature_names = []
        generation_metadata = {}
        
        if parallel and len(generators) > 1:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
            with ThreadPoolExecutor(max_workers=min(len(generators), 4)) as executor:
                future_to_generator = {
                    executor.submit(self.generators[gen_name].generate, data): gen_name
                    for gen_name in generators if gen_name in self.generators
                }
                
                with Progress(
                    SpinnerColumn(),
                    TextColumn("[progress.description]{task.description}"),
                ) as progress:
                    task = progress.add_task("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...", total=len(future_to_generator))
                    
                    for future in as_completed(future_to_generator):
                        gen_name = future_to_generator[future]
                        try:
                            features = future.result()
                            if not features.empty:
                                all_features.append(features)
                                feature_names = self.generators[gen_name].get_feature_names()
                                all_feature_names.extend(feature_names)
                                generation_metadata[gen_name] = {
                                    'feature_count': len(feature_names),
                                    'feature_names': feature_names
                                }
                            progress.advance(task)
                        except Exception as e:
                            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ {gen_name}: {e}")
                            progress.advance(task)
        else:
            # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
            for gen_name in generators:
                if gen_name not in self.generators:
                    continue
                    
                try:
                    features = self.generators[gen_name].generate(data)
                    if not features.empty:
                        all_features.append(features)
                        feature_names = self.generators[gen_name].get_feature_names()
                        all_feature_names.extend(feature_names)
                        generation_metadata[gen_name] = {
                            'feature_count': len(feature_names),
                            'feature_names': feature_names
                        }
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ {gen_name}: {e}")
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if all_features:
            combined_features = pd.concat(all_features, axis=1)
            # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∫–æ–ª–æ–Ω–æ–∫
            combined_features = combined_features.loc[:, ~combined_features.columns.duplicated()]
        else:
            combined_features = pd.DataFrame(index=data.index)
            
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ø—Ä–æ—Å—Ç–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å –ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–æ–π)
        feature_importance = {}
        if not combined_features.empty and len(combined_features.columns) > 1:
            try:
                if 'close' in data.columns:
                    target = data['close']
                else:
                    target = data.iloc[:, 0] if not data.empty else combined_features.iloc[:, 0]
                
                correlations = combined_features.corrwith(target).abs()
                feature_importance = correlations.fillna(0).to_dict()
            except:
                feature_importance = {col: 0.0 for col in combined_features.columns}
        
        processing_time = time.time() - start_time
        
        result = FeatureGenerationResult(
            features=combined_features,
            feature_names=list(combined_features.columns),
            feature_importance=feature_importance,
            generation_metadata=generation_metadata,
            processing_time=processing_time
        )
        
        logger.info(f"‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(result.feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞ {processing_time:.2f}—Å")
        
        return result
    
    def get_feature_importance_ranking(self, result: FeatureGenerationResult) -> List[Tuple[str, float]]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏"""
        return sorted(
            result.feature_importance.items(),
            key=lambda x: x[1],
            reverse=True
        )


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    from ..utils.config_manager import AutoMLConfig
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', periods=1000, freq='1H')
    
    test_data = pd.DataFrame({
        'open': np.random.randn(1000).cumsum() + 50000,
        'high': np.random.randn(1000).cumsum() + 50100,
        'low': np.random.randn(1000).cumsum() + 49900,
        'close': np.random.randn(1000).cumsum() + 50000,
        'volume': np.random.exponential(1000, 1000)
    }, index=dates)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
    config = AutoMLConfig()
    generator = AutoFeatureGenerator(config)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    result = generator.generate_features(test_data)
    
    print(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(result.feature_names)}")
    print(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.processing_time:.2f}—Å")
    print(f"–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {result.generation_metadata}")
    
    # –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    top_features = generator.get_feature_importance_ranking(result)[:10]
    print("\n–¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for name, importance in top_features:
        print(f"  {name}: {importance:.4f}")