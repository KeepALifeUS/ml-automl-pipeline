"""
Advanced Feature Selection for AutoML Pipeline
Implements enterprise patterns for robust feature selection
"""

import logging
from typing import Dict, List, Optional, Tuple, Union, Any, Callable
from dataclasses import dataclass
from abc import ABC, abstractmethod
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from sklearn.feature_selection import (
    SelectKBest, SelectPercentile, SelectFromModel,
    f_regression, f_classif, mutual_info_regression, mutual_info_classif,
    chi2, RFE, RFECV
)
from sklearn.linear_model import LassoCV, ElasticNetCV
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_squared_error, accuracy_score
from sklearn.model_selection import cross_val_score
import xgboost as xgb
from loguru import logger
from pydantic import BaseModel, Field
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
from scipy import stats
from scipy.stats import pearsonr, spearmanr
import matplotlib.pyplot as plt
import seaborn as sns

from ..utils.config_manager import AutoMLConfig


class SelectionMethod(Enum):
    """–ú–µ—Ç–æ–¥—ã –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    STATISTICAL = "statistical"
    MODEL_BASED = "model_based"
    UNIVARIATE = "univariate"
    RECURSIVE = "recursive"
    CORRELATION = "correlation"
    MUTUAL_INFO = "mutual_info"
    VARIANCE = "variance"
    LASSO = "lasso"
    ELASTIC_NET = "elastic_net"


@dataclass
class FeatureSelectionResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    selected_features: List[str]
    feature_scores: Dict[str, float]
    selection_metadata: Dict[str, Any]
    eliminated_features: List[str]
    selection_time: float
    method_used: str


class BaseFeatureSelector(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ -  pattern"""
    
    @abstractmethod
    def select(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> FeatureSelectionResult:
        """–í—ã–±—Ä–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏"""
        pass
    
    @abstractmethod
    def get_selection_params(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ–ª–µ–∫—Ü–∏–∏"""
        pass


class StatisticalFeatureSelector(BaseFeatureSelector):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    
    def __init__(self, method: str = 'f_regression', k: int = 50, percentile: float = 50):
        self.method = method
        self.k = k
        self.percentile = percentile
        self.selector = None
        
        # –í—ã–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
        self.stat_functions = {
            'f_regression': f_regression,
            'f_classif': f_classif,
            'mutual_info_regression': mutual_info_regression,
            'mutual_info_classif': mutual_info_classif,
            'chi2': chi2
        }
        
    def select(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> FeatureSelectionResult:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        import time
        start_time = time.time()
        
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–µ—Ç–æ–¥–æ–º {self.method}")
        
        try:
            # –í—ã–±–æ—Ä —Ñ—É–Ω–∫—Ü–∏–∏ —Å–∫–æ—Ä–∏–Ω–≥–∞
            score_func = self.stat_functions.get(self.method, f_regression)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ—Ç–±–æ—Ä–∞
            if self.k > 0:
                self.selector = SelectKBest(score_func=score_func, k=min(self.k, X.shape[1]))
            else:
                self.selector = SelectPercentile(score_func=score_func, percentile=self.percentile)
            
            # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            X_clean = X.fillna(0).replace([np.inf, -np.inf], 0)
            y_clean = y.fillna(y.mean()) if y.isna().any() else y
            
            # –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            X_selected = self.selector.fit_transform(X_clean, y_clean)
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            selected_mask = self.selector.get_support()
            selected_features = X.columns[selected_mask].tolist()
            eliminated_features = X.columns[~selected_mask].tolist()
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ–≤
            scores = self.selector.scores_
            feature_scores = dict(zip(X.columns, scores))
            
            processing_time = time.time() - start_time
            
            result = FeatureSelectionResult(
                selected_features=selected_features,
                feature_scores=feature_scores,
                selection_metadata={
                    'method': self.method,
                    'k_features': len(selected_features),
                    'original_features': X.shape[1],
                    'reduction_ratio': 1 - len(selected_features) / X.shape[1]
                },
                eliminated_features=eliminated_features,
                selection_time=processing_time,
                method_used=f"statistical_{self.method}"
            )
            
            logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(selected_features)} –∏–∑ {X.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç–±–æ—Ä–∞: {e}")
            return FeatureSelectionResult(
                selected_features=list(X.columns),
                feature_scores={col: 0.0 for col in X.columns},
                selection_metadata={'error': str(e)},
                eliminated_features=[],
                selection_time=time.time() - start_time,
                method_used=f"statistical_{self.method}_failed"
            )
    
    def get_selection_params(self) -> Dict[str, Any]:
        return {
            'method': self.method,
            'k': self.k,
            'percentile': self.percentile
        }


class ModelBasedFeatureSelector(BaseFeatureSelector):
    """–ú–æ–¥–µ–ª—å–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    
    def __init__(self, model_type: str = 'random_forest', max_features: int = 100):
        self.model_type = model_type
        self.max_features = max_features
        self.model = None
        
    def _get_model(self, task_type: str = 'regression'):
        """–ü–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if self.model_type == 'random_forest':
            if task_type == 'regression':
                return RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
            else:
                return RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)
        elif self.model_type == 'xgboost':
            if task_type == 'regression':
                return xgb.XGBRegressor(n_estimators=50, random_state=42, n_jobs=-1)
            else:
                return xgb.XGBClassifier(n_estimators=50, random_state=42, n_jobs=-1)
        else:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é Random Forest
            return RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
    
    def select(self, X: pd.DataFrame, y: pd.Series, task_type: str = 'regression') -> FeatureSelectionResult:
        """–ú–æ–¥–µ–ª—å–Ω—ã–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        import time
        start_time = time.time()
        
        logger.info(f"ü§ñ –ú–æ–¥–µ–ª—å–Ω—ã–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å {self.model_type}")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            X_clean = X.fillna(0).replace([np.inf, -np.inf], 0)
            y_clean = y.fillna(y.mean()) if y.isna().any() else y
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            self.model = self._get_model(task_type)
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            self.model.fit(X_clean, y_clean)
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if hasattr(self.model, 'feature_importances_'):
                importances = self.model.feature_importances_
            elif hasattr(self.model, 'coef_'):
                importances = np.abs(self.model.coef_)
            else:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
                importances = np.abs(X_clean.corrwith(y_clean).fillna(0).values)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –≤–∞–∂–Ω–æ—Å—Ç–∏
            feature_scores = dict(zip(X.columns, importances))
            
            # –û—Ç–±–æ—Ä —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)
            selected_features = [f[0] for f in sorted_features[:self.max_features]]
            eliminated_features = [f[0] for f in sorted_features[self.max_features:]]
            
            processing_time = time.time() - start_time
            
            result = FeatureSelectionResult(
                selected_features=selected_features,
                feature_scores=feature_scores,
                selection_metadata={
                    'model_type': self.model_type,
                    'task_type': task_type,
                    'max_features': self.max_features,
                    'original_features': X.shape[1],
                    'mean_importance': np.mean(importances),
                    'std_importance': np.std(importances)
                },
                eliminated_features=eliminated_features,
                selection_time=processing_time,
                method_used=f"model_{self.model_type}"
            )
            
            logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(selected_features)} —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª—å–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞: {e}")
            return FeatureSelectionResult(
                selected_features=list(X.columns)[:self.max_features],
                feature_scores={col: 0.0 for col in X.columns},
                selection_metadata={'error': str(e)},
                eliminated_features=[],
                selection_time=time.time() - start_time,
                method_used=f"model_{self.model_type}_failed"
            )
    
    def get_selection_params(self) -> Dict[str, Any]:
        return {
            'model_type': self.model_type,
            'max_features': self.max_features
        }


class CorrelationFeatureSelector(BaseFeatureSelector):
    """–°–µ–ª–µ–∫—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏"""
    
    def __init__(self, correlation_threshold: float = 0.95, target_correlation_min: float = 0.01):
        self.correlation_threshold = correlation_threshold
        self.target_correlation_min = target_correlation_min
        
    def select(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> FeatureSelectionResult:
        """–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏"""
        import time
        start_time = time.time()
        
        logger.info("üîó –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            X_clean = X.fillna(0).replace([np.inf, -np.inf], 0)
            y_clean = y.fillna(y.mean()) if y.isna().any() else y
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω–∏–∑–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            target_correlations = X_clean.corrwith(y_clean).abs()
            high_target_corr_features = target_correlations[
                target_correlations >= self.target_correlation_min
            ].index.tolist()
            
            if not high_target_corr_features:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π")
                high_target_corr_features = list(X.columns)
            
            X_filtered = X_clean[high_target_corr_features]
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã—Å–æ–∫–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏—Ö –º–µ–∂–¥—É —Å–æ–±–æ–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            correlation_matrix = X_filtered.corr().abs()
            
            # –ü–æ–∏—Å–∫ –ø–∞—Ä —Å –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π
            high_corr_pairs = []
            for i in range(len(correlation_matrix.columns)):
                for j in range(i+1, len(correlation_matrix.columns)):
                    if correlation_matrix.iloc[i, j] >= self.correlation_threshold:
                        col_i = correlation_matrix.columns[i]
                        col_j = correlation_matrix.columns[j]
                        
                        # –û—Å—Ç–∞–≤–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫ —Å –±–æ–ª—å—à–µ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
                        target_corr_i = abs(target_correlations[col_i])
                        target_corr_j = abs(target_correlations[col_j])
                        
                        if target_corr_i >= target_corr_j:
                            high_corr_pairs.append(col_j)
                        else:
                            high_corr_pairs.append(col_i)
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            features_to_remove = list(set(high_corr_pairs))
            selected_features = [f for f in high_target_corr_features if f not in features_to_remove]
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∫–æ—Ä–æ–≤ (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π)
            feature_scores = target_correlations.to_dict()
            
            processing_time = time.time() - start_time
            
            result = FeatureSelectionResult(
                selected_features=selected_features,
                feature_scores=feature_scores,
                selection_metadata={
                    'correlation_threshold': self.correlation_threshold,
                    'target_correlation_min': self.target_correlation_min,
                    'removed_high_corr': len(features_to_remove),
                    'removed_low_target_corr': len(X.columns) - len(high_target_corr_features)
                },
                eliminated_features=[f for f in X.columns if f not in selected_features],
                selection_time=processing_time,
                method_used="correlation"
            )
            
            logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –æ—Ç–±–æ—Ä–∞: {e}")
            return FeatureSelectionResult(
                selected_features=list(X.columns),
                feature_scores={col: 0.0 for col in X.columns},
                selection_metadata={'error': str(e)},
                eliminated_features=[],
                selection_time=time.time() - start_time,
                method_used="correlation_failed"
            )
    
    def get_selection_params(self) -> Dict[str, Any]:
        return {
            'correlation_threshold': self.correlation_threshold,
            'target_correlation_min': self.target_correlation_min
        }


class VarianceFeatureSelector(BaseFeatureSelector):
    """–°–µ–ª–µ–∫—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏—Å–ø–µ—Ä—Å–∏–∏"""
    
    def __init__(self, variance_threshold: float = 0.0):
        self.variance_threshold = variance_threshold
        
    def select(self, X: pd.DataFrame, y: pd.Series, **kwargs) -> FeatureSelectionResult:
        """–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏"""
        import time
        start_time = time.time()
        
        logger.info("üìà –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            X_clean = X.fillna(0).replace([np.inf, -np.inf], 0)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–∏—Å–ø–µ—Ä—Å–∏–π
            variances = X_clean.var()
            
            # –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
            high_var_features = variances[variances > self.variance_threshold].index.tolist()
            
            feature_scores = variances.to_dict()
            eliminated_features = [f for f in X.columns if f not in high_var_features]
            
            processing_time = time.time() - start_time
            
            result = FeatureSelectionResult(
                selected_features=high_var_features,
                feature_scores=feature_scores,
                selection_metadata={
                    'variance_threshold': self.variance_threshold,
                    'mean_variance': variances.mean(),
                    'removed_low_variance': len(eliminated_features)
                },
                eliminated_features=eliminated_features,
                selection_time=processing_time,
                method_used="variance"
            )
            
            logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(high_var_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–±–æ—Ä–∞ –ø–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏: {e}")
            return FeatureSelectionResult(
                selected_features=list(X.columns),
                feature_scores={col: 0.0 for col in X.columns},
                selection_metadata={'error': str(e)},
                eliminated_features=[],
                selection_time=time.time() - start_time,
                method_used="variance_failed"
            )
    
    def get_selection_params(self) -> Dict[str, Any]:
        return {'variance_threshold': self.variance_threshold}


class AdvancedFeatureSelector:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
    –†–µ–∞–ª–∏–∑—É–µ—Ç enterprise patterns
    """
    
    def __init__(self, config: Optional[AutoMLConfig] = None):
        self.config = config or AutoMLConfig()
        self.selectors: Dict[str, BaseFeatureSelector] = {}
        self._setup_selectors()
        
    def _setup_selectors(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤"""
        logger.info("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        selection_config = self.config.feature_selection
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä
        self.selectors['statistical'] = StatisticalFeatureSelector(
            method=selection_config.get('statistical_method', 'f_regression'),
            k=selection_config.get('statistical_k', 50),
            percentile=selection_config.get('statistical_percentile', 50)
        )
        
        # –ú–æ–¥–µ–ª—å–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
        self.selectors['model'] = ModelBasedFeatureSelector(
            model_type=selection_config.get('model_type', 'random_forest'),
            max_features=selection_config.get('model_max_features', 100)
        )
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
        self.selectors['correlation'] = CorrelationFeatureSelector(
            correlation_threshold=selection_config.get('correlation_threshold', 0.95),
            target_correlation_min=selection_config.get('target_correlation_min', 0.01)
        )
        
        # –°–µ–ª–µ–∫—Ç–æ—Ä –ø–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
        self.selectors['variance'] = VarianceFeatureSelector(
            variance_threshold=selection_config.get('variance_threshold', 0.0)
        )
        
        logger.info(f"‚úÖ –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ {len(self.selectors)} —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤")
    
    def select_features(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        methods: Optional[List[str]] = None,
        task_type: str = 'regression',
        ensemble_selection: bool = True
    ) -> FeatureSelectionResult:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Args:
            X: –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            y: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            methods: –ú–µ—Ç–æ–¥—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏ (regression/classification)
            ensemble_selection: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª—å –º–µ—Ç–æ–¥–æ–≤
        """
        logger.info("üéØ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        if methods is None:
            methods = list(self.selectors.keys())
        
        results = {}
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
        ) as progress:
            task = progress.add_task("–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...", total=len(methods))
            
            for method in methods:
                if method not in self.selectors:
                    continue
                    
                try:
                    progress.update(task, description=f"–ú–µ—Ç–æ–¥: {method}")
                    
                    if method == 'model':
                        result = self.selectors[method].select(X, y, task_type=task_type)
                    else:
                        result = self.selectors[method].select(X, y)
                    
                    results[method] = result
                    progress.advance(task)
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–µ—Ç–æ–¥–µ {method}: {e}")
                    progress.advance(task)
        
        if not results:
            logger.error("‚ùå –ù–∏ –æ–¥–∏–Ω –º–µ—Ç–æ–¥ –æ—Ç–±–æ—Ä–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª")
            return FeatureSelectionResult(
                selected_features=list(X.columns),
                feature_scores={col: 0.0 for col in X.columns},
                selection_metadata={'error': 'All methods failed'},
                eliminated_features=[],
                selection_time=0.0,
                method_used="failed"
            )
        
        if ensemble_selection and len(results) > 1:
            return self._ensemble_selection(X, y, results)
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à–∏–π –º–µ—Ç–æ–¥ (—Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
            best_method = max(results.keys(), key=lambda m: len(results[m].selected_features))
            return results[best_method]
    
    def _ensemble_selection(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        results: Dict[str, FeatureSelectionResult]
    ) -> FeatureSelectionResult:
        """–ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        import time
        start_time = time.time()
        
        logger.info("ü§ù –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –ü–æ–¥—Å—á–µ—Ç –≥–æ–ª–æ—Å–æ–≤ –∑–∞ –∫–∞–∂–¥—ã–π –ø—Ä–∏–∑–Ω–∞–∫
        feature_votes = {}
        all_scores = {}
        
        for method, result in results.items():
            for feature in result.selected_features:
                feature_votes[feature] = feature_votes.get(feature, 0) + 1
                if feature in result.feature_scores:
                    if feature not in all_scores:
                        all_scores[feature] = []
                    all_scores[feature].append(result.feature_scores[feature])
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏—Ö —Å–∫–æ—Ä–æ–≤
        average_scores = {}
        for feature, scores in all_scores.items():
            average_scores[feature] = np.mean(scores)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –≥–æ–ª–æ—Å–æ–≤ (–º–∏–Ω–∏–º—É–º 2 –≥–æ–ª–æ—Å–∞ –∏–∑ 3+ –º–µ—Ç–æ–¥–æ–≤)
        min_votes = max(2, len(results) // 2)
        selected_features = [
            feature for feature, votes in feature_votes.items()
            if votes >= min_votes
        ]
        
        # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø –ø–æ —Å–∫–æ—Ä–∞–º
        if len(selected_features) < 10:
            sorted_by_score = sorted(
                average_scores.items(),
                key=lambda x: x[1],
                reverse=True
            )
            for feature, _ in sorted_by_score:
                if feature not in selected_features:
                    selected_features.append(feature)
                    if len(selected_features) >= 20:  # –ú–∞–∫—Å–∏–º—É–º 20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                        break
        
        eliminated_features = [f for f in X.columns if f not in selected_features]
        processing_time = time.time() - start_time
        
        ensemble_result = FeatureSelectionResult(
            selected_features=selected_features,
            feature_scores=average_scores,
            selection_metadata={
                'ensemble_methods': list(results.keys()),
                'min_votes_threshold': min_votes,
                'feature_votes': feature_votes,
                'total_original_features': X.shape[1]
            },
            eliminated_features=eliminated_features,
            selection_time=processing_time,
            method_used="ensemble"
        )
        
        logger.info(f"‚úÖ –ê–Ω—Å–∞–º–±–ª—å –æ—Ç–æ–±—Ä–∞–ª {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        return ensemble_result
    
    def plot_feature_importance(
        self,
        result: FeatureSelectionResult,
        top_n: int = 20,
        save_path: Optional[str] = None
    ):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        try:
            # –¢–æ–ø N –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
            top_features = sorted(
                result.feature_scores.items(),
                key=lambda x: x[1],
                reverse=True
            )[:top_n]
            
            features, scores = zip(*top_features)
            
            plt.figure(figsize=(12, 8))
            sns.barplot(x=list(scores), y=list(features), palette='viridis')
            plt.title(f'–¢–æ–ø {top_n} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ ({result.method_used})')
            plt.xlabel('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∞')
            plt.ylabel('–ü—Ä–∏–∑–Ω–∞–∫–∏')
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
            else:
                plt.show()
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞: {e}")
    
    def get_selection_report(self, result: FeatureSelectionResult) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –ø–æ –æ—Ç–±–æ—Ä—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        report = f"""
=== –û–¢–ß–ï–¢ –ü–û –û–¢–ë–û–†–£ –ü–†–ò–ó–ù–ê–ö–û–í ===

–ú–µ—Ç–æ–¥: {result.method_used}
–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result.selection_time:.2f}—Å

–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
- –ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(result.selected_features) + len(result.eliminated_features)}
- –û—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(result.selected_features)}
- –ò—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(result.eliminated_features)}
- –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è: {len(result.eliminated_features) / (len(result.selected_features) + len(result.eliminated_features)):.2%}

–¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏:
"""
        
        top_features = sorted(
            result.feature_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )[:10]
        
        for i, (feature, score) in enumerate(top_features, 1):
            report += f"{i:2d}. {feature}: {score:.4f}\n"
        
        report += f"\n–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {result.selection_metadata}"
        
        return report


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    from ..utils.config_manager import AutoMLConfig
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    np.random.seed(42)
    n_samples, n_features = 1000, 100
    
    X = pd.DataFrame(
        np.random.randn(n_samples, n_features),
        columns=[f'feature_{i}' for i in range(n_features)]
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    # –ü–µ—Ä–≤—ã–µ 10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤–∞–∂–Ω—ã–µ, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —à—É–º
    important_features = X.iloc[:, :10].values
    y = pd.Series(
        np.sum(important_features * np.random.randn(10), axis=1) + 
        0.1 * np.random.randn(n_samples)
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞
    config = AutoMLConfig()
    selector = AdvancedFeatureSelector(config)
    
    # –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    result = selector.select_features(X, y, ensemble_selection=True)
    
    print("=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–¢–ë–û–†–ê –ü–†–ò–ó–ù–ê–ö–û–í ===")
    print(f"–û—Ç–æ–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(result.selected_features)}")
    print(f"–í—Ä–µ–º—è –æ—Ç–±–æ—Ä–∞: {result.selection_time:.2f}—Å")
    print(f"–ú–µ—Ç–æ–¥: {result.method_used}")
    
    # –û—Ç—á–µ—Ç
    print(selector.get_selection_report(result))