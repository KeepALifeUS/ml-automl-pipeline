"""
Advanced Ensemble Builder for Crypto Trading AutoML
Implements Context7 enterprise patterns for robust ensemble construction
"""

import logging
from typing import Dict, List, Optional, Tuple, Union, Any, Callable
from dataclasses import dataclass
from abc import ABC, abstractmethod
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score, KFold, TimeSeriesSplit
from sklearn.ensemble import VotingRegressor, VotingClassifier
from sklearn.linear_model import Ridge, LinearRegression, LogisticRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin
import xgboost as xgb
import lightgbm as lgb
from loguru import logger
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
from rich.console import Console
from rich.table import Table
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import time

from ..utils.config_manager import AutoMLConfig


class EnsembleMethod(Enum):
    """–ú–µ—Ç–æ–¥—ã –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è"""
    VOTING = "voting"
    STACKING = "stacking"
    BLENDING = "blending"
    BAGGING = "bagging"
    DYNAMIC_WEIGHTING = "dynamic_weighting"


@dataclass
class EnsembleResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è"""
    ensembles: Dict[str, Any]
    ensemble_scores: Dict[str, float]
    best_ensemble_method: str
    best_ensemble_score: float
    base_model_scores: Dict[str, float]
    ensemble_weights: Dict[str, Dict[str, float]]
    ensemble_metadata: Dict[str, Any]
    build_time: float


class BaseEnsembleBuilder(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª–µ–π –∞–Ω—Å–∞–º–±–ª–µ–π - Context7 pattern"""
    
    @abstractmethod
    def build(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        models: Dict[str, Any],
        **kwargs
    ) -> Any:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∞–Ω—Å–∞–º–±–ª—å"""
        pass


class VotingEnsembleBuilder(BaseEnsembleBuilder):
    """–°—Ç—Ä–æ–∏—Ç–µ–ª—å –≥–æ–ª–æ—Å—É—é—â–µ–≥–æ –∞–Ω—Å–∞–º–±–ª—è"""
    
    def __init__(self, voting_type: str = 'soft', weights: Optional[List[float]] = None):
        self.voting_type = voting_type
        self.weights = weights
        
    def build(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        models: Dict[str, Any],
        task_type: str = 'regression',
        **kwargs
    ) -> Any:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥–æ–ª–æ—Å—É—é—â–∏–π –∞–Ω—Å–∞–º–±–ª—å"""
        logger.info(f"üó≥Ô∏è –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥–æ–ª–æ—Å—É—é—â–µ–≥–æ –∞–Ω—Å–∞–º–±–ª—è ({self.voting_type})")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è
        estimators = [(name, model) for name, model in models.items()]
        
        try:
            if task_type == 'regression':
                ensemble = VotingRegressor(
                    estimators=estimators,
                    weights=self.weights
                )
            else:
                ensemble = VotingClassifier(
                    estimators=estimators,
                    voting=self.voting_type,
                    weights=self.weights
                )
            
            # –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è
            ensemble.fit(X, y)
            
            logger.info(f"‚úÖ –ì–æ–ª–æ—Å—É—é—â–∏–π –∞–Ω—Å–∞–º–±–ª—å –ø–æ—Å—Ç—Ä–æ–µ–Ω —Å {len(models)} –º–æ–¥–µ–ª—è–º–∏")
            
            return ensemble
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥–æ–ª–æ—Å—É—é—â–µ–≥–æ –∞–Ω—Å–∞–º–±–ª—è: {e}")
            return None


class StackingEnsembleBuilder(BaseEnsembleBuilder):
    """–°—Ç—Ä–æ–∏—Ç–µ–ª—å —Å—Ç–µ–∫–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—è"""
    
    def __init__(
        self,
        meta_learner: Optional[Any] = None,
        cv_folds: int = 5,
        use_features_in_secondary: bool = True
    ):
        self.meta_learner = meta_learner
        self.cv_folds = cv_folds
        self.use_features_in_secondary = use_features_in_secondary
        
    def build(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        models: Dict[str, Any],
        task_type: str = 'regression',
        **kwargs
    ) -> Any:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å—Ç–µ–∫–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—å"""
        logger.info("ü•û –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å—Ç–µ–∫–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—è")
        
        try:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–µ—Ç–∞-–æ–±—É—á–∞—é—â–µ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if self.meta_learner is None:
                if task_type == 'regression':
                    self.meta_learner = Ridge(alpha=1.0)
                else:
                    self.meta_learner = LogisticRegression(max_iter=1000)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–µ–∫–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—è
            from sklearn.ensemble import StackingRegressor, StackingClassifier
            
            estimators = [(name, model) for name, model in models.items()]
            
            if task_type == 'regression':
                ensemble = StackingRegressor(
                    estimators=estimators,
                    final_estimator=self.meta_learner,
                    cv=self.cv_folds,
                    passthrough=self.use_features_in_secondary,
                    n_jobs=-1
                )
            else:
                ensemble = StackingClassifier(
                    estimators=estimators,
                    final_estimator=self.meta_learner,
                    cv=self.cv_folds,
                    passthrough=self.use_features_in_secondary,
                    n_jobs=-1
                )
            
            # –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è
            ensemble.fit(X, y)
            
            logger.info(f"‚úÖ –°—Ç–µ–∫–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—å –ø–æ—Å—Ç—Ä–æ–µ–Ω —Å {len(models)} –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏")
            
            return ensemble
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å—Ç–µ–∫–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—è: {e}")
            return None


class BlendingEnsembleBuilder(BaseEnsembleBuilder):
    """–°—Ç—Ä–æ–∏—Ç–µ–ª—å –±–ª–µ–Ω–¥–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—è"""
    
    def __init__(
        self,
        holdout_size: float = 0.2,
        meta_learner: Optional[Any] = None
    ):
        self.holdout_size = holdout_size
        self.meta_learner = meta_learner
        self.base_models = None
        self.blending_predictions = None
        
    def build(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        models: Dict[str, Any],
        task_type: str = 'regression',
        **kwargs
    ) -> Any:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –±–ª–µ–Ω–¥–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—å"""
        logger.info("üîÄ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –±–ª–µ–Ω–¥–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—è")
        
        try:
            from sklearn.model_selection import train_test_split
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –±–ª–µ–Ω–¥–∏–Ω–≥
            X_base, X_blend, y_base, y_blend = train_test_split(
                X, y,
                test_size=self.holdout_size,
                random_state=42
            )
            
            # –û–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
            trained_models = {}
            blend_predictions = []
            
            for name, model in models.items():
                # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ø–∏–∏ –º–æ–¥–µ–ª–∏ –¥–ª—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
                if hasattr(model, 'copy'):
                    trained_model = model.copy()
                else:
                    from sklearn.base import clone
                    trained_model = clone(model)
                
                # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –±–∞–∑–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ
                trained_model.fit(X_base, y_base)
                trained_models[name] = trained_model
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –±–ª–µ–Ω–¥–∏–Ω–≥ –Ω–∞–±–æ—Ä–µ
                predictions = trained_model.predict(X_blend)
                blend_predictions.append(predictions)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–µ—Ç–∞-–æ–±—É—á–µ–Ω–∏—è
            blend_features = np.column_stack(blend_predictions)
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–µ—Ç–∞-–∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if self.meta_learner is None:
                if task_type == 'regression':
                    self.meta_learner = Ridge(alpha=1.0)
                else:
                    self.meta_learner = LogisticRegression(max_iter=1000)
            
            # –û–±—É—á–µ–Ω–∏–µ –º–µ—Ç–∞-–∞–ª–≥–æ—Ä–∏—Ç–º–∞
            self.meta_learner.fit(blend_features, y_blend)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è
            ensemble = BlendingEnsemble(
                base_models=trained_models,
                meta_learner=self.meta_learner
            )
            
            logger.info(f"‚úÖ –ë–ª–µ–Ω–¥–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—å –ø–æ—Å—Ç—Ä–æ–µ–Ω —Å {len(models)} –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏")
            
            return ensemble
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –±–ª–µ–Ω–¥–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—è: {e}")
            return None


class BlendingEnsemble(BaseEstimator, RegressorMixin):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π –±–ª–µ–Ω–¥–∏–Ω–≥ –∞–Ω—Å–∞–º–±–ª—å"""
    
    def __init__(self, base_models: Dict[str, Any], meta_learner: Any):
        self.base_models = base_models
        self.meta_learner = meta_learner
        
    def fit(self, X, y):
        # –ú–æ–¥–µ–ª–∏ —É–∂–µ –æ–±—É—á–µ–Ω—ã –≤ BlendingEnsembleBuilder
        return self
        
    def predict(self, X):
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ—Ç –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        base_predictions = []
        for name, model in self.base_models.items():
            predictions = model.predict(X)
            base_predictions.append(predictions)
        
        # –°—Ç–µ–∫–∏–Ω–≥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        stacked_predictions = np.column_stack(base_predictions)
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–µ—Ç–∞-–∞–ª–≥–æ—Ä–∏—Ç–º–æ–º
        final_predictions = self.meta_learner.predict(stacked_predictions)
        
        return final_predictions


class DynamicWeightingEnsemble(BaseEstimator, RegressorMixin):
    """–ê–Ω—Å–∞–º–±–ª—å —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –≤–µ—Å–∞–º–∏"""
    
    def __init__(self, models: Dict[str, Any], window_size: int = 100):
        self.models = models
        self.window_size = window_size
        self.weights_history = []
        self.performance_history = {name: [] for name in models.keys()}
        
    def fit(self, X, y):
        # –û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        for name, model in self.models.items():
            model.fit(X, y)
        
        return self
        
    def predict(self, X):
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ—Ç –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        predictions = {}
        for name, model in self.models.items():
            predictions[name] = model.predict(X)
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–≤–Ω—ã–µ –≤–µ—Å–∞
        if not self.weights_history:
            weights = {name: 1.0 / len(self.models) for name in self.models.keys()}
        else:
            weights = self._calculate_dynamic_weights()
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        final_predictions = np.zeros(len(X))
        for name, weight in weights.items():
            final_predictions += weight * predictions[name]
        
        return final_predictions
    
    def _calculate_dynamic_weights(self):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–¥–∞–≤–Ω–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - —Ä–∞–≤–Ω—ã–µ –≤–µ—Å–∞
        return {name: 1.0 / len(self.models) for name in self.models.keys()}


class EnsembleBuilder:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª–µ–π
    –†–µ–∞–ª–∏–∑—É–µ—Ç Context7 enterprise patterns
    """
    
    def __init__(self, config: Optional[AutoMLConfig] = None):
        self.config = config or AutoMLConfig()
        self.ensemble_config = self.config.ensemble
        self.console = Console()
        
        # –°—Ç—Ä–æ–∏—Ç–µ–ª–∏ –∞–Ω—Å–∞–º–±–ª–µ–π
        self.ensemble_builders: Dict[str, BaseEnsembleBuilder] = {}
        self._setup_builders()
        
    def _setup_builders(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª–µ–π –∞–Ω—Å–∞–º–±–ª–µ–π"""
        logger.info("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª–µ–π –∞–Ω—Å–∞–º–±–ª–µ–π...")
        
        if self.ensemble_config.enable_voting:
            self.ensemble_builders['voting'] = VotingEnsembleBuilder(
                voting_type='soft',
                weights=self.ensemble_config.voting_weights
            )
        
        if self.ensemble_config.enable_stacking:
            self.ensemble_builders['stacking'] = StackingEnsembleBuilder(
                cv_folds=self.ensemble_config.stacking_cv_folds,
                use_features_in_secondary=self.ensemble_config.stacking_use_features_in_secondary
            )
        
        if self.ensemble_config.enable_blending:
            self.ensemble_builders['blending'] = BlendingEnsembleBuilder(
                holdout_size=self.ensemble_config.blending_holdout_size
            )
        
        logger.info(f"‚úÖ –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ {len(self.ensemble_builders)} —Å—Ç—Ä–æ–∏—Ç–µ–ª–µ–π –∞–Ω—Å–∞–º–±–ª–µ–π")
    
    def build_ensemble(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        models: Dict[str, Any],
        ensemble_methods: Optional[List[str]] = None,
        task_type: str = 'regression'
    ) -> EnsembleResult:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª–µ–π
        
        Args:
            X: –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            y: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            models: –°–ª–æ–≤–∞—Ä—å –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
            ensemble_methods: –ú–µ—Ç–æ–¥—ã –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏ (regression/classification)
        """
        start_time = time.time()
        
        logger.info(f"ü§ù –ó–∞–ø—É—Å–∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª–µ–π —Å {len(models)} –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏")
        
        if ensemble_methods is None:
            ensemble_methods = list(self.ensemble_builders.keys())
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π –≤ –∞–Ω—Å–∞–º–±–ª–µ
        if len(models) > self.ensemble_config.ensemble_size_limit:
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –æ—Ç–±–æ—Ä –ª—É—á—à–∏—Ö
            sorted_models = self._rank_models_by_performance(X, y, models, task_type)
            models = dict(list(sorted_models.items())[:self.ensemble_config.ensemble_size_limit])
            logger.info(f"üìù –û–≥—Ä–∞–Ω–∏—á–µ–Ω—ã –¥–æ {len(models)} –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è")
        
        ensembles = {}
        ensemble_scores = {}
        ensemble_weights = {}
        base_model_scores = {}
        
        # –û—Ü–µ–Ω–∫–∞ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        base_model_scores = self._evaluate_base_models(X, y, models, task_type)
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–π
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
        ) as progress:
            
            task = progress.add_task("–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–π...", total=len(ensemble_methods))
            
            for method in ensemble_methods:
                progress.update(task, description=f"–ú–µ—Ç–æ–¥: {method}")
                
                if method not in self.ensemble_builders:
                    logger.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è: {method}")
                    continue
                
                try:
                    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è
                    ensemble = self.ensemble_builders[method].build(
                        X, y, models, task_type=task_type
                    )
                    
                    if ensemble is not None:
                        ensembles[method] = ensemble
                        
                        # –û—Ü–µ–Ω–∫–∞ –∞–Ω—Å–∞–º–±–ª—è
                        score = self._evaluate_ensemble(X, y, ensemble, task_type)
                        ensemble_scores[method] = score
                        
                        # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–µ—Å–æ–≤ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
                        weights = self._extract_ensemble_weights(ensemble, method)
                        if weights:
                            ensemble_weights[method] = weights
                        
                        logger.info(f"‚úÖ {method} –∞–Ω—Å–∞–º–±–ª—å: —Å–∫–æ—Ä {score:.4f}")
                
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è {method} –∞–Ω—Å–∞–º–±–ª—è: {e}")
                
                progress.advance(task)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ –∞–Ω—Å–∞–º–±–ª—è
        if ensemble_scores:
            best_method = max(ensemble_scores.keys(), key=lambda k: ensemble_scores[k])
            best_score = ensemble_scores[best_method]
        else:
            best_method = "none"
            best_score = 0.0
            logger.warning("‚ö†Ô∏è –ù–∏ –æ–¥–∏–Ω –∞–Ω—Å–∞–º–±–ª—å –Ω–µ –±—ã–ª —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω")
        
        build_time = time.time() - start_time
        
        result = EnsembleResult(
            ensembles=ensembles,
            ensemble_scores=ensemble_scores,
            best_ensemble_method=best_method,
            best_ensemble_score=best_score,
            base_model_scores=base_model_scores,
            ensemble_weights=ensemble_weights,
            ensemble_metadata={
                'task_type': task_type,
                'base_models_count': len(models),
                'ensemble_methods_tried': len(ensemble_methods),
                'successful_ensembles': len(ensembles)
            },
            build_time=build_time
        )
        
        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self._print_ensemble_results(result)
        
        logger.info(f"‚úÖ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {build_time:.2f}—Å")
        
        return result
    
    def _rank_models_by_performance(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        models: Dict[str, Any],
        task_type: str
    ) -> Dict[str, Any]:
        """–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        logger.info("üìä –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
        
        model_scores = {}
        
        for name, model in models.items():
            try:
                # –ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ —Å 3-fold CV
                if task_type == 'regression':
                    scores = cross_val_score(model, X, y, cv=3, scoring='r2', n_jobs=-1)
                else:
                    scores = cross_val_score(model, X, y, cv=3, scoring='accuracy', n_jobs=-1)
                
                model_scores[name] = np.mean(scores)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏ {name}: {e}")
                model_scores[name] = 0.0
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å–∫–æ—Ä–∞
        ranked_models = dict(
            sorted(model_scores.items(), key=lambda x: x[1], reverse=True)
        )
        
        return {name: models[name] for name in ranked_models.keys()}
    
    def _evaluate_base_models(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        models: Dict[str, Any],
        task_type: str
    ) -> Dict[str, float]:
        """–û—Ü–µ–Ω–∫–∞ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        logger.info("üìè –û—Ü–µ–Ω–∫–∞ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π...")
        
        base_scores = {}
        
        for name, model in models.items():
            try:
                if task_type == 'regression':
                    scores = cross_val_score(model, X, y, cv=3, scoring='r2', n_jobs=-1)
                else:
                    scores = cross_val_score(model, X, y, cv=3, scoring='accuracy', n_jobs=-1)
                
                base_scores[name] = np.mean(scores)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ {name}: {e}")
                base_scores[name] = 0.0
        
        return base_scores
    
    def _evaluate_ensemble(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        ensemble: Any,
        task_type: str
    ) -> float:
        """–û—Ü–µ–Ω–∫–∞ –∞–Ω—Å–∞–º–±–ª—è"""
        try:
            if task_type == 'regression':
                scores = cross_val_score(ensemble, X, y, cv=3, scoring='r2', n_jobs=-1)
            else:
                scores = cross_val_score(ensemble, X, y, cv=3, scoring='accuracy', n_jobs=-1)
            
            return np.mean(scores)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –∞–Ω—Å–∞–º–±–ª—è: {e}")
            return 0.0
    
    def _extract_ensemble_weights(self, ensemble: Any, method: str) -> Optional[Dict[str, float]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∞–Ω—Å–∞–º–±–ª—è"""
        try:
            if method == 'voting' and hasattr(ensemble, 'estimators_'):
                if hasattr(ensemble, 'weights') and ensemble.weights is not None:
                    estimator_names = [name for name, _ in ensemble.estimators]
                    return dict(zip(estimator_names, ensemble.weights))
            
            elif method == 'stacking' and hasattr(ensemble, 'final_estimator_'):
                if hasattr(ensemble.final_estimator_, 'coef_'):
                    estimator_names = [name for name, _ in ensemble.estimators]
                    weights = ensemble.final_estimator_.coef_
                    if len(weights) >= len(estimator_names):
                        return dict(zip(estimator_names, weights[:len(estimator_names)]))
            
            return None
            
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≤–µ—Å–∞ –¥–ª—è {method}: {e}")
            return None
    
    def _print_ensemble_results(self, result: EnsembleResult):
        """–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è"""
        
        # –¢–∞–±–ª–∏—Ü–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω—Å–∞–º–±–ª–µ–π
        table = Table(title="ü§ù –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–°–ê–ú–ë–õ–ò–†–û–í–ê–ù–ò–Ø")
        
        table.add_column("–ú–µ—Ç–æ–¥", style="cyan", no_wrap=True)
        table.add_column("–°–∫–æ—Ä", style="green")
        table.add_column("–£–ª—É—á—à–µ–Ω–∏–µ", style="magenta")
        
        # –õ—É—á—à–∏–π –±–∞–∑–æ–≤—ã–π —Å–∫–æ—Ä –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        best_base_score = max(result.base_model_scores.values()) if result.base_model_scores else 0.0
        
        for method, score in sorted(result.ensemble_scores.items(), key=lambda x: x[1], reverse=True):
            improvement = ((score - best_base_score) / best_base_score * 100) if best_base_score > 0 else 0.0
            table.add_row(
                method,
                f"{score:.4f}",
                f"+{improvement:.2f}%" if improvement > 0 else f"{improvement:.2f}%"
            )
        
        self.console.print(table)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ª—É—á—à–µ–º –∞–Ω—Å–∞–º–±–ª–µ
        if result.best_ensemble_method != "none":
            best_info = f"""
üèÜ –õ—É—á—à–∏–π –∞–Ω—Å–∞–º–±–ª—å: {result.best_ensemble_method}
üìä –°–∫–æ—Ä: {result.best_ensemble_score:.4f}
‚è±Ô∏è –í—Ä–µ–º—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è: {result.build_time:.2f}—Å
üî¢ –ë–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: {result.ensemble_metadata['base_models_count']}
"""
            self.console.print(best_info)
    
    def plot_ensemble_comparison(
        self,
        result: EnsembleResult,
        save_path: Optional[str] = None
    ):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª–µ–π"""
        try:
            fig, axes = plt.subplots(1, 2, figsize=(15, 6))
            
            # –ì—Ä–∞—Ñ–∏–∫ 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ–≤
            all_scores = {**result.base_model_scores, **result.ensemble_scores}
            sorted_scores = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)
            
            methods, scores = zip(*sorted_scores)
            colors = ['red' if method in result.ensemble_scores else 'blue' for method in methods]
            
            axes[0].barh(methods, scores, color=colors, alpha=0.7)
            axes[0].set_xlabel('–°–∫–æ—Ä')
            axes[0].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –∞–Ω—Å–∞–º–±–ª–µ–π')
            axes[0].grid(True, alpha=0.3)
            
            # –õ–µ–≥–µ–Ω–¥–∞
            axes[0].axvline(x=0, color='blue', alpha=0.7, label='–ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏')
            axes[0].axvline(x=0, color='red', alpha=0.7, label='–ê–Ω—Å–∞–º–±–ª–∏')
            axes[0].legend()
            
            # –ì—Ä–∞—Ñ–∏–∫ 2: –£–ª—É—á—à–µ–Ω–∏—è –æ—Ç –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            if result.ensemble_scores and result.base_model_scores:
                best_base_score = max(result.base_model_scores.values())
                
                improvements = {}
                for method, score in result.ensemble_scores.items():
                    improvement = ((score - best_base_score) / best_base_score * 100) if best_base_score > 0 else 0.0
                    improvements[method] = improvement
                
                if improvements:
                    methods, improve_values = zip(*improvements.items())
                    colors = ['green' if imp > 0 else 'orange' for imp in improve_values]
                    
                    axes[1].bar(methods, improve_values, color=colors, alpha=0.7)
                    axes[1].set_ylabel('–£–ª—É—á—à–µ–Ω–∏–µ (%)')
                    axes[1].set_title('–£–ª—É—á—à–µ–Ω–∏–µ –æ—Ç –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è')
                    axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)
                    axes[1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ –∞–Ω—Å–∞–º–±–ª–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
            else:
                plt.show()
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ –∞–Ω—Å–∞–º–±–ª–µ–π: {e}")
    
    def get_ensemble_report(self, result: EnsembleResult) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –ø–æ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—é"""
        
        report = f"""
=== –û–¢–ß–ï–¢ –ü–û –ê–ù–°–ê–ú–ë–õ–ò–†–û–í–ê–ù–ò–Æ ===

–ë–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: {len(result.base_model_scores)}
–ú–µ—Ç–æ–¥–æ–≤ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è: {len(result.ensemble_scores)}
–í—Ä–µ–º—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è: {result.build_time:.2f}—Å

–õ—É—á—à–∏–π –∞–Ω—Å–∞–º–±–ª—å: {result.best_ensemble_method}
–õ—É—á—à–∏–π —Å–∫–æ—Ä: {result.best_ensemble_score:.4f}

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω—Å–∞–º–±–ª–µ–π:
"""
        
        for method, score in sorted(result.ensemble_scores.items(), key=lambda x: x[1], reverse=True):
            report += f"  {method}: {score:.4f}\n"
        
        # –í–µ—Å–∞ –∞–Ω—Å–∞–º–±–ª–µ–π
        if result.ensemble_weights:
            report += "\n–í–µ—Å–∞ –≤ –∞–Ω—Å–∞–º–±–ª—è—Ö:\n"
            for method, weights in result.ensemble_weights.items():
                report += f"  {method}:\n"
                for model, weight in weights.items():
                    report += f"    {model}: {weight:.3f}\n"
        
        report += f"\n–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {result.ensemble_metadata}"
        
        return report


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è EnsembleBuilder
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import Ridge
    import xgboost as xgb
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    np.random.seed(42)
    n_samples, n_features = 1000, 20
    
    X = pd.DataFrame(
        np.random.randn(n_samples, n_features),
        columns=[f'feature_{i}' for i in range(n_features)]
    )
    
    y = pd.Series(
        X.iloc[:, :5].sum(axis=1) + 0.1 * np.random.randn(n_samples)
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
    models = {
        'ridge': Ridge(alpha=1.0),
        'random_forest': RandomForestRegressor(n_estimators=50, random_state=42),
        'xgboost': xgb.XGBRegressor(n_estimators=50, random_state=42)
    }
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π
    config = AutoMLConfig()
    builder = EnsembleBuilder(config)
    
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–π
    result = builder.build_ensemble(
        X, y, models,
        ensemble_methods=['voting', 'stacking'],
        task_type='regression'
    )
    
    print("=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–°–ê–ú–ë–õ–ò–†–û–í–ê–ù–ò–Ø ===")
    print(f"–õ—É—á—à–∏–π –∞–Ω—Å–∞–º–±–ª—å: {result.best_ensemble_method}")
    print(f"–õ—É—á—à–∏–π —Å–∫–æ—Ä: {result.best_ensemble_score:.4f}")
    print(f"–í—Ä–µ–º—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è: {result.build_time:.2f}—Å")
    
    # –û—Ç—á–µ—Ç
    print(builder.get_ensemble_report(result))